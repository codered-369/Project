

<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="applicable-device" content="pc,mobile">
    <meta name="access" content="Yes">

    
    
    <meta name="twitter:site" content="@SpringerLink"/>
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:title" content="EfficientNet deep learning meta-classifier approach for image-based android malware detection"/>
    <meta name="twitter:description" content="Multimedia Tools and Applications - A survey of literature shows that transforming the application files into images and employing deep learning-based models for image classification has been..."/>
    <meta name="journal_id" content="11042"/>
    <meta name="dc.title" content="EfficientNet deep learning meta-classifier approach for image-based android malware detection"/>
    <meta name="dc.source" content="Multimedia Tools and Applications 2022"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Springer"/>
    <meta name="dc.date" content="2022-12-14"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2022 The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature"/>
    <meta name="dc.rights" content="2022 The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature"/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="A survey of literature shows that transforming the application files into images and employing deep learning-based models for image classification has been considered as one of the significant directions for malware detection and classification. Mainly, convolutional neural networks (CNN)-based models are successfully employed for Android malware detection and classification. This is mainly due to the reason that this type of malware detection and classification approach is platform independent and has the capability to detect metamorphic and polymorphic malware. The Image-based Android malware detection is resilient to both unpacked and packed malware. Following, this work employs various 26 CNN-based pretrained models and the detailed investigation and analysis of experiments are shown on the Image-based Android malware dataset. Each of these models have the capability to extract its own optimal features and these features are distinct to each other. The penultimate layer features of best performed CNN-based pretrained models are extracted and dimensionality of the features were reduced using kernel principal component analysis (KPCA). The reduced features were fused together and passed into a meta-classifier or stacked classifier for classification. This classifier has two levels; in the first level support vector machine (SVM) and random forest (RForest) machine learning classifier were included for prediction and logistic regression in the second level for classification. The four combinations of fused models are DenseNet, ResNet, InceptionResNet, and EfficientNet. EfficientNet-based fused models showed better performances compared to other fused models and non-fused CNN-based pretrained models. Moreover, the EfficientNet-based fused models outperformed the existing approaches for Android malware detection. All the model performances were shown on two different testing datasets and the proposed model has shown the similar performances on both the testing datasets with attaining better performances during training and testing. This indicates that the proposed model is more generalizable, robust, and it can be used as tool that can be deployed in any application play store."/>
    <meta name="prism.issn" content="1573-7721"/>
    <meta name="prism.publicationName" content="Multimedia Tools and Applications"/>
    <meta name="prism.publicationDate" content="2022-12-14"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="1"/>
    <meta name="prism.endingPage" content="27"/>
    <meta name="prism.copyright" content="2022 The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature"/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://link-springer-com.vtutest.mapmyaccess.com/article/10.1007/s11042-022-14236-6"/>
    <meta name="prism.doi" content="doi:10.1007/s11042-022-14236-6"/>
    <meta name="citation_pdf_url" content="https://link-springer-com.vtutest.mapmyaccess.com/content/pdf/10.1007/s11042-022-14236-6.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://link-springer-com.vtutest.mapmyaccess.com/article/10.1007/s11042-022-14236-6"/>
    <meta name="citation_journal_title" content="Multimedia Tools and Applications"/>
    <meta name="citation_journal_abbrev" content="Multimed Tools Appl"/>
    <meta name="citation_publisher" content="Springer US"/>
    <meta name="citation_issn" content="1573-7721"/>
    <meta name="citation_title" content="EfficientNet deep learning meta-classifier approach for image-based android malware detection"/>
    <meta name="citation_online_date" content="2022/12/14"/>
    <meta name="citation_firstpage" content="1"/>
    <meta name="citation_lastpage" content="27"/>
    <meta name="citation_article_type" content="Article"/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1007/s11042-022-14236-6"/>
    <meta name="DOI" content="10.1007/s11042-022-14236-6"/>
    <meta name="size" content="216730"/>
    <meta name="citation_doi" content="10.1007/s11042-022-14236-6"/>
    <meta name="citation_springer_api_url" content="http://api.springer-com.vtutest.mapmyaccess.com/xmldata/jats?q=doi:10.1007/s11042-022-14236-6&amp;api_key="/>
    <meta name="description" content="A survey of literature shows that transforming the application files into images and employing deep learning-based models for image classification has been"/>
    <meta name="dc.creator" content="Ravi, Vinayakumar"/>
    <meta name="dc.creator" content="Chaganti, Rajasekhar"/>
    <meta name="dc.subject" content="Multimedia Information Systems"/>
    <meta name="dc.subject" content="Computer Communication Networks"/>
    <meta name="dc.subject" content="Data Structures and Information Theory"/>
    <meta name="dc.subject" content="Special Purpose and Application-Based Systems"/>
    <meta name="citation_reference" content="Android Malware (2021) Volume statistics, 16 March 2021. 
                https://www.statista.com/statistics/680705/global-android-malware-volume/
                
              "/>
    <meta name="citation_reference" content="Arslan RS, Amd-cnn MT (2022) Android malware detection via feature graph and convolutional neural networks. Concurrency Computat Pract Experience, p e7180"/>
    <meta name="citation_reference" content="Awotunde JB, Ajagbe SA, Oladipupo MA, Awokola JA, Afolabi OS, Mathew TO, Oguns YJ (2021) An improved machine learnings diagnosis technique for covid-19 pandemic using chest x-ray images. In: International conference on applied informatics. Springer, pp 319&#8211;330"/>
    <meta name="citation_reference" content="Bakour K, &#220;nver HM (2020) Visdroid: android malware classification based on local and global image features, bag of visual words and machine learning techniques. Neural Comput Appl:1&#8211;21"/>
    <meta name="citation_reference" content="citation_journal_title=Neural Comput Appl; citation_title=Deepvisdroid: android malware detection by hybridizing image-based features with deep learning techniques; citation_author=K Bakour, HM &#220;nver; citation_volume=33; citation_issue=18; citation_publication_date=2021; citation_pages=11499-11516; citation_doi=10.1007/s00521-021-05816-y; citation_id=CR5"/>
    <meta name="citation_reference" content="Chen H, Du R, Liu Z, Xu H (2018) Android malware classification using xgboost based on images patterns. In: 2018 IEEE 4th information technology and mechatronics engineering conference (ITOEC). IEEE, pp 1358&#8211;1362"/>
    <meta name="citation_reference" content="citation_journal_title=Digit Investig; citation_title=A malware classification method based on memory dump grayscale image; citation_author=Y Dai, H Li, Y Qian, X Lu; citation_volume=27; citation_publication_date=2018; citation_pages=30-37; citation_doi=10.1016/j.diin.2018.09.006; citation_id=CR7"/>
    <meta name="citation_reference" content="Darus FM, Ahmad NA, Mohd Ariffin AF (2019) Android malware classification using xgboost on data image pattern. In: 2019 IEEE international conference on internet of things and intelligence system (iotaIS). IEEE, pp 118&#8211;122"/>
    <meta name="citation_reference" content="Darus FM, Salleh NAA, Mohd Ariffin AF (2018) Android malware detection using machine learning on image patterns. In: 2018 Cyber resilience conference (CRC). IEEE, pp 1&#8211;2"/>
    <meta name="citation_reference" content="De Oliveira AS, Sassi RJ (2020) Chimera: an android malware detection method based on multimodal deep learning and hybrid analysis"/>
    <meta name="citation_reference" content="Ding Y, Wu R, Xue F (2018) Detecting android malware using bytecode image. In: International conference on cognitive computing. Springer, pp 164&#8211;169"/>
    <meta name="citation_reference" content="Ding Y, Zhang X, Hu J, Xu W (2020) Android malware detection method based on bytecode image. J Ambient Intell Humanized Comput:1&#8211;10"/>
    <meta name="citation_reference" content="Galov N (2021) 21+ Exciting android statistics to keep your eyes on in 2021"/>
    <meta name="citation_reference" content="Gu S, Cheng S, Zhang W (2020) From image to code: executable adversarial examples of android applications. In: Proceedings of the 2020 6th international conference on computing and artificial intelligence, pp 261&#8211;268"/>
    <meta name="citation_reference" content="Guerra-Manzanares A, Bahsi H (2022) On the relativity of time: implications and challenges of data drift on long-term effective android malware detection. Comput Secur, p 102835"/>
    <meta name="citation_reference" content="Guerra-Manzanares A, Valbe M (2022) Cross-device behavioral consistency: benchmarking and implications for effective android malware detection. Mach Learn Appl, p 100357"/>
    <meta name="citation_reference" content="He P, Gan G (2020) Android malicious app detection based on cnn deep learning algorithm. In: IOP conference series: earth and environmental science. IOP publishing, vol 428, pp 012061"/>
    <meta name="citation_reference" content="Huang W, Hou E, Zheng L, Feng W (2018) Mixdroid: a multi-features and multi-classifiers bagging system for android malware detection. In: AIP conference proceedings. AIP publishing LLC, vol 1967, pp 020015"/>
    <meta name="citation_reference" content="Huang TH-D, Kao H-Y (2018) R2-d2: color-inspired convolutional neural network (cnn)-based android malware detections. In: 2018 IEEE international conference on big data (big data). IEEE, pp 2633&#8211;2642"/>
    <meta name="citation_reference" content="citation_journal_title=Comput Secur; citation_title=Android malware detection as a bi-level problem; citation_author=M Jerbi, ZC Dagdia, S Bechikh, LB Said; citation_volume=121; citation_publication_date=2022; citation_pages=102825; citation_doi=10.1016/j.cose.2022.102825; citation_id=CR20"/>
    <meta name="citation_reference" content="Jung J, Choi J, Cho S-J, Han S, Park M, Hwang Y (2018) Android malware detection using convolutional neural networks and data section images. In: Proceedings of the 2018 conference on research in adaptive and convergent systems, pp 149&#8211;153"/>
    <meta name="citation_reference" content="Kumar A, Pramod Sagar K, Kuppusamy KS, Aghila G (2016) Machine learning based malware classification for android applications using multimodal image representations. In: 2016 10th International conference on intelligent systems and control (ISCO). IEEE, pp 1&#8211;6"/>
    <meta name="citation_reference" content="citation_journal_title=Electronics; citation_title=Automatic face mask detection system in public transportation in smart cities using iot and deep learning; citation_author=TA Kumar, R Rajmohan, M Pavithra, SA Ajagbe, R Hodhod, T Gaber; citation_volume=11; citation_issue=6; citation_publication_date=2022; citation_pages=904; citation_doi=10.3390/electronics11060904; citation_id=CR23"/>
    <meta name="citation_reference" content="Lachtar N, Ibdah D, Bacha A (2020) Towards mobile malware detection through convolutional neural networks. IEEE Embedded Syst Lett"/>
    <meta name="citation_reference" content="Lakshmanan R (2021) New android malware steals financial data from 378 banking and wallet apps"/>
    <meta name="citation_reference" content="Lekssays A, Falah B, Abufardeh S (2020) A novel approach for android malware detection and classification using convolutional neural networks. In: ICSOFT 2020 - proceedings of the 15th international conference on software technologies, (Icsoft), pp 606&#8211;614"/>
    <meta name="citation_reference" content="Malware (2021) Statistics, 16 March 2021. 
                https://www.av-test.org/en/statistics/malware/
                
              "/>
    <meta name="citation_reference" content="Mercaldo F, Santone A (2020) Deep learning for image-based mobile malware detection. J Comput Virology Hacking Tech:1&#8211;15"/>
    <meta name="citation_reference" content="Muzaffar A, Hassen HR, Lones MA, Zantout H (2022) An in-depth review of machine learning based android malware detection. Comput Secur:102833"/>
    <meta name="citation_reference" content="Naeem H, Guo B, Ullah F, Naeem MR (2019) A cross-platform malware variant classification based on image representation. KSII Trans Internet Inf Syst, vol 13(7)"/>
    <meta name="citation_reference" content="Qiu J, Zhang J, Luo W, Pan L, Nepal S, Xiang Y (2020) A survey of android malware detection with deep neural models. ACM Comput Surv, vol 53(6)"/>
    <meta name="citation_reference" content="Rafiq H, Aslam N, Ahmed U, Lin JC-W (2022) Mitigating malicious adversaries evasion attacks in industrial internet of things. IEEE Trans Industr Inf"/>
    <meta name="citation_reference" content="Rahali A, Lashkari AH, Kaur G, Taheri L, Gagnon F, Massicotte F (2020) DIDroid: android malware classification and characterization using deep image learning. PervasiveHealth: Pervasive Comput Technol Healthcare:70&#8211;82"/>
    <meta name="citation_reference" content="citation_journal_title=Comput Electr Eng; citation_title=Machine learning-assisted signature and heuristic-based detection of malwares in android devices; citation_author=Z-U Rehman, SN Khan, K Muhammad, JW Lee, Z Lv, SW Baik, PA Shah, K Awan, I Mehmood; citation_volume=69; citation_publication_date=2018; citation_pages=828-841; citation_doi=10.1016/j.compeleceng.2017.11.028; citation_id=CR34"/>
    <meta name="citation_reference" content="citation_journal_title=Ad Hoc Netw; citation_title=End-to-end malware detection for android iot devices using deep learning; citation_author=Z Ren, H Wu, Q Ning, I Hussain, B Chen; citation_volume=101; citation_publication_date=2020; citation_pages=102098; citation_doi=10.1016/j.adhoc.2020.102098; citation_id=CR35"/>
    <meta name="citation_reference" content="Selvaganapathy S, Sadasivam S, Ravi V (2021) A review on android malware: attacks countermeasures and challenges ahead. J Cyber Secur Mobility:177&#8211;230"/>
    <meta name="citation_reference" content="citation_journal_title=Sensors; citation_title=Deep feature extraction and classification of android malware images; citation_author=J Singh, D Thakur, F Ali, T Gera, KS Kwak; citation_volume=20; citation_issue=24; citation_publication_date=2020; citation_pages=7013; citation_doi=10.3390/s20247013; citation_id=CR37"/>
    <meta name="citation_reference" content="Singh J, Thakur D, Gera T, Shah B, Abuhmed T, Ali F (2021) Classification and analysis of android malware images using feature fusion technique. IEEE Access, vol 9"/>
    <meta name="citation_reference" content="Su X, Zhang D, Li W, Zhao K (2016) A deep learning approach to android malware feature learning and detection. In: 2016 IEEE trustcom/bigdataSE/ISPA. IEEE, pp 244&#8211;251"/>
    <meta name="citation_reference" content="Tan M, Le QV (2019) Efficientnet: rethinking model scaling for convolutional neural networks. CoRR arXiv:
                1905.11946
                
              "/>
    <meta name="citation_reference" content="citation_journal_title=SN Appl Sci; citation_title=Android malware detection based on image-based features and machine learning techniques; citation_author=HM &#220;nver, K Bakour; citation_volume=2; citation_issue=7; citation_publication_date=2020; citation_pages=1-15; citation_doi=10.1007/s42452-020-3132-2; citation_id=CR41"/>
    <meta name="citation_reference" content="citation_journal_title=J Inf Secur Appl; citation_title=A hybrid deep learning image-based analysis for effective malware detection; citation_author=S Venkatraman, M Alazab, R Vinayakumar; citation_volume=47; citation_publication_date=2019; citation_pages=377-389; citation_id=CR42"/>
    <meta name="citation_reference" content="citation_journal_title=IEEE Access; citation_title=Robust intelligent malware detection using deep learning; citation_author=R Vinayakumar, M Alazab, KP Soman, P Poornachandran, S Venkatraman; citation_volume=7; citation_publication_date=2019; citation_pages=46717-46738; citation_doi=10.1109/ACCESS.2019.2906934; citation_id=CR43"/>
    <meta name="citation_reference" content="Vinayakumar R, Soman KP, Poornachandran P (2017) Deep android malware detection and classification. In: 2017 International conference on advances in computing, communications and informatics (ICACCI). IEEE, pp 1677&#8211;1683"/>
    <meta name="citation_reference" content="citation_journal_title=J Intell Fuzzy Syst; citation_title=Detecting android malware using long short-term memory (lstm); citation_author=R Vinayakumar, KP Soman, P Poornachandran, S Sachin Kumar; citation_volume=34; citation_issue=3; citation_publication_date=2018; citation_pages=1277-1288; citation_doi=10.3233/JIFS-169424; citation_id=CR45"/>
    <meta name="citation_reference" content="citation_journal_title=Neural Netw; citation_title=Stacked generalization; citation_author=DH Wolpert; citation_volume=5; citation_issue=2; citation_publication_date=1992; citation_pages=241-259; citation_doi=10.1016/S0893-6080(05)80023-1; citation_id=CR46"/>
    <meta name="citation_reference" content="Yang S (2019) An image-inspired and cnn-based android malware detection approach. In: Proceedings of the 34th IEEE/ACM international conference on automated software engineering, pp 1259&#8211;1261"/>
    <meta name="citation_reference" content="Yang M, Wen Q (2017) Detecting android malware by applying classification techniques on images patterns. In: 2017 IEEE 2nd international conference on cloud computing and big data analysis (ICCCBDA). IEEE, pp 344&#8211;347"/>
    <meta name="citation_reference" content="citation_journal_title=Microelectron Reliab; citation_title=An android mutation malware detection based on deep learning using visualization of importance from codes; citation_author=Y-S Yen, H-M Sun; citation_volume=93; citation_publication_date=2019; citation_pages=109-114; citation_doi=10.1016/j.microrel.2019.01.007; citation_id=CR49"/>
    <meta name="citation_reference" content="Yumlembam R, Issac B, Jacob SM, Yang L (2022) Iot-based android malware detection using graph neural network with adversarial defense. IEEE Internet Things J"/>
    <meta name="citation_reference" content="Zhang W, Luktarhan N, Ding C, Lu B (2021) Android malware detection using tcn with bytecode image. Symmetry, vol 13(7)"/>
    <meta name="citation_reference" content="Zhang H, Qin J, Zhang B, Yan H, Guo J, Gao F, Wang S, Hu Y (2020) A multiclass detection system for android malicious apps based on color image features. Wirel Commun Mob Comput, vol 2020"/>
    <meta name="citation_reference" content="Zhao J, Masood R, Seneviratne S (2021) A review of computer vision methods in network security. IEEE Commun Surveys Tutorials"/>
    <meta name="citation_author" content="Ravi, Vinayakumar"/>
    <meta name="citation_author_email" content="vravi@pmu.edu.sa"/>
    <meta name="citation_author_institution" content="Center for Artificial Intelligence, Prince Mohammad Bin Fahd University, Khobar, Saudi Arabia"/>
    <meta name="citation_author" content="Chaganti, Rajasekhar"/>
    <meta name="citation_author_email" content="Raj.chaganti2@gmail.com"/>
    <meta name="citation_author_institution" content="Department of Computer Science, University of Texas at San Antonio, San Antonio, USA"/>
    <meta name="format-detection" content="telephone=no"/>
    

    
    
    <meta property="og:url" content="https://link-springer-com.vtutest.mapmyaccess.com/article/10.1007/s11042-022-14236-6"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="SpringerLink"/>
    <meta property="og:title" content="EfficientNet deep learning meta-classifier approach for image-based android malware detection - Multimedia Tools and Applications"/>
    <meta property="og:description" content="A survey of literature shows that transforming the application files into images and employing deep learning-based models for image classification has been considered as one of the significant directions for malware detection and classification. Mainly, convolutional neural networks (CNN)-based models are successfully employed for Android malware detection and classification. This is mainly due to the reason that this type of malware detection and classification approach is platform independent and has the capability to detect metamorphic and polymorphic malware. The Image-based Android malware detection is resilient to both unpacked and packed malware. Following, this work employs various 26 CNN-based pretrained models and the detailed investigation and analysis of experiments are shown on the Image-based Android malware dataset. Each of these models have the capability to extract its own optimal features and these features are distinct to each other. The penultimate layer features of best performed CNN-based pretrained models are extracted and dimensionality of the features were reduced using kernel principal component analysis (KPCA). The reduced features were fused together and passed into a meta-classifier or stacked classifier for classification. This classifier has two levels; in the first level support vector machine (SVM) and random forest (RForest) machine learning classifier were included for prediction and logistic regression in the second level for classification. The four combinations of fused models are DenseNet, ResNet, InceptionResNet, and EfficientNet. EfficientNet-based fused models showed better performances compared to other fused models and non-fused CNN-based pretrained models. Moreover, the EfficientNet-based fused models outperformed the existing approaches for Android malware detection. All the model performances were shown on two different testing datasets and the proposed model has shown the similar performances on both the testing datasets with attaining better performances during training and testing. This indicates that the proposed model is more generalizable, robust, and it can be used as tool that can be deployed in any application play store."/>
    <meta property="og:image" content="https://media.springernature.com/w200/springer-static/cover/journal/11042.jpg"/>
    


    <title>EfficientNet deep learning meta-classifier approach for image-based android malware detection | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) { a{text-decoration:underline;text-decoration-skip-ink:auto}html{text-size-adjust:100%;-webkit-font-smoothing:subpixel-antialiased;box-sizing:border-box;color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:100%;height:100%;line-height:1.61803;overflow-y:scroll}body{background:#fcfcfc;font-size:1.125rem;line-height:1.5;max-width:100%;min-height:100%}article,aside,header,main,nav,section{display:block}h1{font-size:2em;margin:.67em 0}a{background-color:transparent;color:#004b83;overflow-wrap:break-word;word-break:break-word}b{font-weight:bolder}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}svg:not(:root){overflow:hidden}button,input{font-family:sans-serif;font-size:100%}input{line-height:1.15}button,input{overflow:visible}button{text-transform:none}[type=submit],button,html [type=button]{-webkit-appearance:button}[hidden]{display:none}button{border-radius:0;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;line-height:inherit}h1,h2{font-family:Georgia,Palatino,serif;font-weight:400}h1{font-size:2.25rem;font-style:normal;margin-bottom:1em}h2{font-size:1.75rem}.u-h4,h2,h3{font-style:normal;margin-bottom:1em}h3{font-family:Georgia,Palatino,serif;font-size:1.5rem;font-weight:400}.u-h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem}.c-reading-companion__figure-title,.u-h4{font-weight:700;line-height:1.4}.c-reading-companion__figure-title{font-size:1.25rem;font-style:normal}.c-reading-companion__figure-title,label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}*{box-sizing:inherit}body,button,div,form,input{margin:0;padding:0}p{padding:0}h1,h2,h3{line-height:1.4}p{margin:0}h1,h2,h3,ul{margin-top:0}p{margin-bottom:1.5em;overflow-wrap:break-word;word-break:break-word}p:last-child{margin-bottom:0}p:empty{display:none}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}.c-ad--728x90 iframe{height:90px;max-width:970px}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}.js .u-show-following-ad+.c-ad--728x90{display:block}}.c-ad iframe{border:0;overflow:auto;vertical-align:top}.c-ad__label{color:#333;font-weight:400;line-height:1.5;margin-bottom:4px}.c-ad__label,.c-skip-link{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem}.c-skip-link{background:#f7fbfe;bottom:auto;color:#004b83;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#004b83}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #ccc;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-pagination{align-items:center;display:flex;flex-wrap:wrap;font-size:.875rem;list-style:none;margin:0;padding:16px}@media only screen and (min-width:540px){.c-pagination{justify-content:center}}.c-pagination__item{margin-bottom:8px;margin-right:16px}.c-pagination__item:last-child{margin-right:0}.c-pagination__link{align-items:center;background-color:#f2f2f2;background-image:linear-gradient(#fff,#f2f2f2);border:1px solid #ccc;border-radius:2px;color:#004b83;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;min-width:30px;padding:8px;position:relative;text-align:center;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.c-pagination__link svg,.c-pagination__link--disabled svg{fill:currentcolor}.c-pagination__link:visited{color:#004b83}.c-pagination__link:focus,.c-pagination__link:hover{border:1px solid #666;text-decoration:none}.c-pagination__link:focus,.c-pagination__link:hover{background-color:#666;background-image:none;color:#fff}.c-pagination__link:focus svg path,.c-pagination__link:hover svg path{fill:#fff}.c-pagination__link--disabled{align-items:center;background-color:transparent;background-image:none;border-radius:2px;color:#333;cursor:default;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;opacity:.67;padding:8px;position:relative;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.c-pagination__link--disabled:visited{color:#333}.c-pagination__link--disabled,.c-pagination__link--disabled:focus,.c-pagination__link--disabled:hover{border:1px solid #ccc;text-decoration:none}.c-pagination__link--disabled:focus,.c-pagination__link--disabled:hover{background-color:transparent;background-image:none;color:#333}.c-pagination__link--disabled:focus svg path,.c-pagination__link--disabled:hover svg path{fill:#333}.c-pagination__link--active{background-color:#666;background-image:none;border-color:#666;color:#fff;cursor:default}.c-pagination__ellipsis{background:0 0;border:0;min-width:auto;padding-left:0;padding-right:0}.c-pagination__icon{fill:#999;height:12px;width:16px}.c-pagination__icon--active{fill:#004b83}.c-header{background-color:#fff;border-bottom:4px solid #00285a;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;padding:16px 0}.c-header__container,.c-header__menu{align-items:center;display:flex;flex-wrap:wrap}@supports (gap:2em){.c-header__container,.c-header__menu{gap:2em 2em}}.c-header__menu{list-style:none;margin:0;padding:0}.c-header__item{color:inherit}@supports not (gap:2em){.c-header__item{margin-left:24px}}.c-header__container{justify-content:space-between;margin:0 auto;max-width:1280px;padding:0 16px}@supports not (gap:2em){.c-header__brand{margin-right:32px}}.c-header__brand a{display:block;text-decoration:none}.c-header__link{color:inherit}.c-popup-search{background-color:#eee;box-shadow:0 3px 3px -3px rgba(0,0,0,.21);padding:16px 0;position:relative;z-index:10}@media only screen and (min-width:1024px){.js .c-popup-search{position:absolute;top:100%;width:100%}.c-popup-search__container{margin:auto;max-width:70%}}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin-bottom:16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg{margin:1px 4px 0 0}.c-article-author-list__button:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:0 0 16px}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Georgia,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-code-block{border:1px solid #f2f2f2;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-associated-content__container .c-article-associated-content__collection-label{line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fcfcfc;border-bottom:1px solid #fcfcfc;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-reading-companion__panel--active{display:block}.c-article-section__figure-description{font-size:1rem}.c-article-section__figure-description>*{margin-bottom:0}.c-cod{display:block;font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff}.c-pdf-download__link .u-icon{padding-top:2px}.save-data .c-article-author-institutional-author__sub-division,.save-data .c-article-equation__number,.save-data .c-article-figure-description,.save-data .c-article-fullwidth-content,.save-data .c-article-main-column,.save-data .c-article-satellite-article-link,.save-data .c-article-satellite-subtitle,.save-data .c-article-table-container,.save-data .c-blockquote__body,.save-data .c-code-block__heading,.save-data .c-reading-companion__figure-title,.save-data .c-reading-companion__reference-citation,.save-data .c-site-messages--nature-briefing-email-variant .serif,.save-data .c-site-messages--nature-briefing-email-variant.serif,.save-data .serif,.save-data .u-serif,.save-data h1,.save-data h2,.save-data h3{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px!important}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-article-extras .c-pdf-container{flex-wrap:wrap;width:100%}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.app-search__content{display:flex}.app-search__label{color:#666;display:inline-block;font-size:.875rem;margin-bottom:8px}.app-search__input{border:1px solid #b3b3b3;border-bottom-left-radius:3px;border-top-left-radius:3px;box-shadow:inset 0 1px 3px 0 rgba(0,0,0,.21);flex:0 1 auto;font-size:.875rem;line-height:1.2;padding:.75em 1em;vertical-align:middle;width:100%}.app-search__button{align-items:center;background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.5);border-radius:0 2px 2px 0;color:#fff;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-align:center;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:50px}.app-search__button svg,.u-button svg,.u-button--primary svg{fill:currentcolor}.app-checklist-banner{border:2px solid #ebf1f5;display:flex;flex:1 1 auto;font-size:1rem;justify-content:space-between;margin-bottom:16px;padding:16px}.app-checklist-banner--on-mobile{display:block;margin-bottom:32px}@media only screen and (min-width:1024px){.app-checklist-banner--on-mobile{display:none}}.app-checklist-banner__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;font-weight:700;margin-bottom:0}.app-checklist-banner__icon-container{align-items:center;display:flex;flex:0 0 60px;justify-content:end;width:60px}.app-checklist-banner__link{align-items:center;color:#004b83;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.app-checklist-banner__arrow-icon,.app-checklist-banner__paper-icon{fill:currentcolor;display:inline-block;transform:translate(0);vertical-align:text-top}.app-checklist-banner__paper-icon{height:36px!important;width:36px!important}.app-checklist-banner__arrow-icon{height:11px;margin:4px 0 0 8px;width:16px}.u-button{align-items:center;background-color:#f2f2f2;background-image:linear-gradient(#fff,#f2f2f2);border:1px solid #ccc;border-radius:2px;color:#004b83;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.5);color:#fff}.u-button--full-width{display:flex;width:100%}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-display-block{display:block}.u-display-flex{display:flex;width:100%}.u-align-items-center{align-items:center}.u-justify-content-space-between{justify-content:space-between}.u-flex-static{flex:0 0 auto}.u-display-none{display:none}.js .u-js-hide{display:none;visibility:hidden}@media print{.u-hide-print{display:none}}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-list-reset{list-style:none;margin:0;padding:0}.u-button-reset{background-color:transparent;border:0;padding:0}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-position-relative{position:relative}.u-mt-0{margin-top:0}.u-mt-32{margin-top:32px}.u-mr-24{margin-right:24px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.u-ml-8{margin-left:8px}.u-float-left{float:left}.u-hide{display:none;visibility:hidden}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.u-text-sm{font-size:1rem}.hide{display:none;visibility:hidden}.visually-hidden{clip:rect(1px,1px,1px,1px);height:1px;position:absolute!important;width:1px}.c-article-section__figure-description{font-family:Georgia,Palatino,serif}.c-article-section__content p{line-height:1.8}.c-pagination__input{border:1px solid #bfbfbf;border-radius:2px;box-shadow:inset 0 2px 6px 0 rgba(51,51,51,.2);box-sizing:initial;display:inline-block;height:28px;margin:0;max-width:64px;min-width:16px;padding:0 8px;text-align:center;transition:width .15s ease 0s}.c-pagination__input::-webkit-inner-spin-button,.c-pagination__input::-webkit-outer-spin-button{-webkit-appearance:none;margin:0}@media only screen and (min-width:1024px){.c-article-collection__container{display:none}}.c-article-associated-content__container .c-article-associated-content__collection-label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.063rem}.c-article-associated-content__container .c-article-associated-content__collection-title{font-size:1.063rem;font-weight:400}.c-reading-companion__sections-list{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-section__title,.c-article-title{font-weight:400}.c-header__cart-icon{margin-right:12px}.c-header__navigation{display:flex} }</style>



    <link rel="stylesheet" data-test="critical-css-handler" data-inline-css-source="critical-css" href="/oscar-static/app-springerlink/css/enhanced-article-9314391185.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    


    
    <script>
        window.dataLayer = [{"GA Key":"UA-26408784-1","DOI":"10.1007/s11042-022-14236-6","Page":"article","springerJournal":true,"page":{"attributes":{"environment":"live","featureFlags":[{"name":"ab_test_article_journal_header","active":true}]}},"Country":"IN","japan":false,"doi":"10.1007-s11042-022-14236-6","Journal Title":"Multimedia Tools and Applications","Journal Id":11042,"Keywords":"Cybersecurity, Cybercrime, Android, Malware, Deep learning, Transfer learning, Feature fusion, Meta-classifier","kwrd":["Cybersecurity","Cybercrime","Android","Malware","Deep_learning","Transfer_learning","Feature_fusion","Meta-classifier"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"N","hasAccess":"N","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-s11042-022-14236-6","Full HTML":"N","Subject Codes":["SCI","SCI18059","SCI13022","SCI15009","SCI13030"],"pmc":["I","I18059","I13022","I15009","I13030"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1573-7721","pissn":"1380-7501"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Multimedia Information Systems","2":"Computer Communication Networks","3":"Data Structures and Information Theory","4":"Special Purpose and Application-Based Systems"},"secondarySubjectCodes":{"1":"I18059","2":"I13022","3":"I15009","4":"I13030"}},"sucode":"SC6"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article"}];
    </script>

    <script>
    window.dataLayer.push({
        ga4MeasurementId: 'G-B3E4QL2TPR',
        ga360TrackingId: 'UA-26408784-1',
        twitterId: 'o47a7',
        ga4ServerUrl: 'https://collect.springer-com.vtutest.mapmyaccess.com',
        imprint: 'springerlink'
    });
</script>

    <script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://collect.springer-com.vtutest.mapmyaccess.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('springer-com.vtutest.mapmyaccess.com') > -1) {
                e.src = 'https://cmp-static.springer-com.vtutest.mapmyaccess.com/production_live/consent-bundle-17-26.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = '/static/js/lib/cookie-consent.min.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>

    <script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
        }
    })(window, document.documentElement);
</script>


    
<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>



    <script class="js-entry">
    if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
                window.suppressShareButton = false;
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-1b7e24bf66.js', 'async': false},
                {'src': '/oscar-static/js/airbrake-es5-bundle-b5b00885bf.js', 'async': false},
            ];

            var bodyScripts = [
                
                    {'src': '/oscar-static/js/app-es5-bundle-bd11d7e283.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/app-es6-bundle-85e2a51854.js', 'async': false, 'module': true}
                
                
                
                    , {'src': '/oscar-static/js/global-article-es5-bundle-44b22c1a09.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-30815be4d0.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
</script>

    
    
    <link rel="canonical" href="https://link-springer-com.vtutest.mapmyaccess.com/article/10.1007/s11042-022-14236-6"/>
    

    
    <script type="application/ld+json">{"mainEntity":{"headline":"EfficientNet deep learning meta-classifier approach for image-based android malware detection","description":"A survey of literature shows that transforming the application files into images and employing deep learning-based models for image classification has been considered as one of the significant directions for malware detection and classification. Mainly, convolutional neural networks (CNN)-based models are successfully employed for Android malware detection and classification. This is mainly due to the reason that this type of malware detection and classification approach is platform independent and has the capability to detect metamorphic and polymorphic malware. The Image-based Android malware detection is resilient to both unpacked and packed malware. Following, this work employs various 26 CNN-based pretrained models and the detailed investigation and analysis of experiments are shown on the Image-based Android malware dataset. Each of these models have the capability to extract its own optimal features and these features are distinct to each other. The penultimate layer features of best performed CNN-based pretrained models are extracted and dimensionality of the features were reduced using kernel principal component analysis (KPCA). The reduced features were fused together and passed into a meta-classifier or stacked classifier for classification. This classifier has two levels; in the first level support vector machine (SVM) and random forest (RForest) machine learning classifier were included for prediction and logistic regression in the second level for classification. The four combinations of fused models are DenseNet, ResNet, InceptionResNet, and EfficientNet. EfficientNet-based fused models showed better performances compared to other fused models and non-fused CNN-based pretrained models. Moreover, the EfficientNet-based fused models outperformed the existing approaches for Android malware detection. All the model performances were shown on two different testing datasets and the proposed model has shown the similar performances on both the testing datasets with attaining better performances during training and testing. This indicates that the proposed model is more generalizable, robust, and it can be used as tool that can be deployed in any application play store.","datePublished":"2022-12-14","dateModified":"2022-12-14","pageStart":"1","pageEnd":"27","sameAs":"https://doi.org/10.1007/s11042-022-14236-6","keywords":"Multimedia Information Systems,Computer Communication Networks,Data Structures and Information Theory,Special Purpose and Application-Based Systems","image":"https://static-content.springer.com/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig1_HTML.png","isPartOf":{"name":"Multimedia Tools and Applications","issn":["1573-7721","1380-7501"],"@type":["Periodical"]},"publisher":{"name":"Springer US","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Ravi, Vinayakumar","affiliation":[{"name":"Prince Mohammad Bin Fahd University","address":{"name":"Center for Artificial Intelligence, Prince Mohammad Bin Fahd University, Khobar, Saudi Arabia","@type":"PostalAddress"},"@type":"Organization"}],"email":"vravi@pmu.edu.sa","@type":"Person"},{"name":"Chaganti, Rajasekhar","affiliation":[{"name":"University of Texas at San Antonio","address":{"name":"Department of Computer Science, University of Texas at San Antonio, San Antonio, USA","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>

</head>
<body class="shared-article-renderer">
    
    
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript data-test="gtm-body">
                <iframe src="https://collect.springer-com.vtutest.mapmyaccess.com/ns.html?id=GTM-MRVXSHQ"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    


    <div class="u-vh-full">
        <a class="c-skip-link" href="#main-content">Skip to main content</a>
        
            <div class="u-hide u-show-following-ad"></div>
            <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
                <div class="c-ad__inner">
                    <p class="c-ad__label">Advertisement</p>
                    <div id="div-gpt-ad-LB1" data-pa11y-ignore data-gpt data-test="LB1-ad"
                         data-gpt-unitpath="/270604982/springerlink/11042/article" data-gpt-sizes="728x90"
                         style="min-width:728px;min-height:90px" data-gpt-targeting="pos=LB1;articleid=s11042-022-14236-6;"></div>
                </div>
            </aside>


<div class="u-position-relative u-mbs-0">
        <header class="c-header u-mb-24" data-test="publisher-header">
    
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-6c9a864b59.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                <span>Search</span>
                <svg class="u-icon u-flex-static u-ml-8" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>

        <div class="c-header__cart-icon">
            <div id="ecommerce-header-cart-icon-link" class="c-header__item ecommerce-cart" style="display:inline-block;margin-right:10px">
 <form action="https://order.springer-com.vtutest.mapmyaccess.com/public/precheckout" method="post">
  <button class="c-header__link" type="submit" style="appearance:none;border:none;background:none;color:inherit;position:relative">
   <svg aria-hidden="true" focusable="false" height="18" viewbox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg" style="vertical-align:text-bottom">
    <path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z" fill="#333"></path>
   </svg><span class="u-screenreader-only visually-hidden">Go to cart</span><span class="cart-info" style="display:none;position:absolute;top:-4px;right:-10px;background-color:#C40606;color:#fff;width:18px;height:18px;font-size:11px;border-radius:50%;line-height:17.5px;text-align:center"></span></button>
 </form>
 <script>(function () { var exports = {}; if (window.fetch) {
            
            "use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.headerWidgetClientInit = void 0;
var headerWidgetClientInit = function (getCartInfo) {
    console.log("listen to updatedCart event");
    document.body.addEventListener("updatedCart", function () {
        console.log("updatedCart happened");
        updateCartIcon().then(function () { return console.log("Cart state update upon event"); });
    }, false);
    return updateCartIcon().then(function () { return console.log("Initial cart state update"); });
    function updateCartIcon() {
        return getCartInfo()
            .then(function (res) { return res.json(); })
            .then(refreshCartState)
            .catch(function () { return console.log("Could not fetch cart info"); });
    }
    function refreshCartState(json) {
        var indicator = document.querySelector("#ecommerce-header-cart-icon-link .cart-info");
        /* istanbul ignore else */
        if (indicator && json.itemCount) {
            indicator.style.display = 'block';
            indicator.textContent = json.itemCount > 9 ? '9+' : json.itemCount.toString();
            var moreThanOneItem = json.itemCount > 1;
            indicator.setAttribute('title', "there ".concat(moreThanOneItem ? "are" : "is", " ").concat(json.itemCount, " item").concat(moreThanOneItem ? "s" : "", " in your cart"));
        }
        return json;
    }
};
exports.headerWidgetClientInit = headerWidgetClientInit;

            
            headerWidgetClientInit(
              function () {
                return window.fetch("https://cart.springer-com.vtutest.mapmyaccess.com/cart-info", {
                  credentials: "include",
                  headers: { Accept: "application/json" }
                })
              }
            )
        }})()</script>
</div>
        </div>

        <nav>
            <ul class="c-header__menu">
                
        
            <li class="c-header__item">
                <a
                    data-test="login-link"
                    class="c-header__link"
                    href="https://link-springer-com.vtutest.mapmyaccess.com/signup-login?previousUrl=https%3A%2F%2Flink-springer-com.vtutest.mapmyaccess.com%2Farticle%2F10.1007%2Fs11042-022-14236-6"
                    data-track="click"
                    data-track-category="header"
                    data-track-action="login header"
                    data-track-label="link">Log in</a>
            </li>
        

        


            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        
            <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
                <div class="c-popup-search__content">
                    <div class="u-container">
                        <div class="c-popup-search__container" data-test="springerlink-popup-search">
                            <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="u-icon" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                        </div>
                    </div>
                </div>
            </div>
        
    
</div>

        
            
    
        <nav class="u-container" aria-label="breadcrumbs" data-test="article-breadcrumbs">
            <ol class="c-breadcrumbs c-breadcrumbs--truncated" itemscope itemtype="https://schema.org/BreadcrumbList">
                
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/" class="c-breadcrumbs__link" itemprop="item" data-track="click" data-track-category="article" data-track-action="breadcrumbs" data-track-label="breadcrumb1"><span itemprop="name">Home</span></a><meta itemprop="position" content="1">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/journal/11042" class="c-breadcrumbs__link" itemprop="item" data-track="click" data-track-category="article" data-track-action="breadcrumbs" data-track-label="breadcrumb2"><span itemprop="name">Multimedia Tools and Applications</span></a><meta itemprop="position" content="2">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <span itemprop="name">Article</span><meta itemprop="position" content="3">
                    </li>
                
            </ol>
        </nav>
    

        


        
    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
            
                
                <div class="c-context-bar u-hide"
                     data-test="context-bar"
                     data-context-bar
                     aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            EfficientNet deep learning meta-classifier approach for image-based android malware detection
                        </div>
                        
                            <div data-test="inCoD">
                                
    <div class="c-pdf-container">
        <div class="c-pdf-download u-clear-both u-mb-16">
            <a href="/content/pdf/10.1007/s11042-022-14236-6.pdf?pdf=button" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" data-track-external download>
                
                    <span class="c-pdf-download__text">Download PDF</span>
                    <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
                
            </a>
        </div>
    </div>


                            </div>
                        
                    </div>
                    
<div id="recommendations">
    <div class="c-recommendations__container u-container u-display-none" data-component-recommendations>
        <aside class="c-status-message c-status-message--success u-display-none" data-component-status-msg>
            <svg class="c-status-message__icon" width="24" height="24" role="img" aria-label="success:" focusable="false">
                <use xlink:href="#icon-success"></use>
            </svg>
            <div class="c-status-message__message" tabindex="-1" id="success-message">
                Your article has downloaded
            </div>
        </aside>

        <div class="c-recommendations-header u-display-flex u-justify-content-space-between">
            <h2 class="c-recommendations-title" id="recommendation-heading">Similar articles being viewed by others</h2>
            <button class="c-recommendations-close u-flex-static" type="button" aria-label="Close" data-track="click" data-track-action="close recommendations">
                <svg class="u-icon" width="16" height="16" aria-hidden="true" focusable="false"><use xlink:href="#icon-close"></use></svg>
            </button>
        </div>

        <section aria-roledescription="carousel" aria-labelledby="recommendation-heading">
            <p class="u-visually-hidden">Slider with three articles shown per slide. Use the Previous and Next buttons to navigate the slides or the slide controller buttons at the end to navigate through each slide.</p>
            <div class="c-recommendations-list-container">
                <div class="c-recommendations-list">
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 1 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1007%2Fs00521-021-05816-y/MediaObjects/521_2021_5816_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1007/s00521-021-05816-y" data-track="click" data-track-action="click recommendations" data-track-label="10.1007/s00521-021-05816-y">DeepVisDroid: android malware detection by hybridizing image-based features with deep learning techniques</a></h3>
                                        <p class="u-sans-serif u-mb-0">04 March 2021</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Khaled Bakour &amp; Halil Murat nver</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 2 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1007%2Fs12083-021-01244-w/MediaObjects/12083_2021_1244_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1007/s12083-021-01244-w" data-track="click" data-track-action="click recommendations" data-track-label="10.1007/s12083-021-01244-w">MINAD: Multi-inputs Neural Network based on Application Structure for Android Malware Detection</a></h3>
                                        <p class="u-sans-serif u-mb-0">14 September 2021</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Duc V. Nguyen, Giang L. Nguyen,  Giang T. Pham</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 3 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1007%2Fs00521-020-05195-w/MediaObjects/521_2020_5195_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1007/s00521-020-05195-w" data-track="click" data-track-action="click recommendations" data-track-label="10.1007/s00521-020-05195-w">VisDroid: Android malware classification based on local and global image features, bag of visual words and machine learning techniques</a></h3>
                                        <p class="u-sans-serif u-mb-0">20 July 2020</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Khaled Bakour &amp; Halil Murat nver</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 4 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1007%2Fs12652-018-0803-6/MediaObjects/12652_2018_803_Fig1_HTML.gif" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1007/s12652-018-0803-6" data-track="click" data-track-action="click recommendations" data-track-label="10.1007/s12652-018-0803-6">Effective android malware detection with a hybrid model based on deep autoencoder and convolutional neural network</a></h3>
                                        <p class="u-sans-serif u-mb-0">28 April 2018</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Wei Wang, Mengxue Zhao &amp; Jigang Wang</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 5 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1007%2Fs11416-019-00346-7/MediaObjects/11416_2019_346_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1007/s11416-019-00346-7" data-track="click" data-track-action="click recommendations" data-track-label="10.1007/s11416-019-00346-7">Deep learning for image-based mobile malware detection</a></h3>
                                        <p class="u-sans-serif u-mb-0">13 January 2020</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Francesco Mercaldo &amp; Antonella Santone</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 6 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1007%2Fs12652-020-02196-4/MediaObjects/12652_2020_2196_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1007/s12652-020-02196-4" data-track="click" data-track-action="click recommendations" data-track-label="10.1007/s12652-020-02196-4">Android malware detection method based on bytecode image</a></h3>
                                        <p class="u-sans-serif u-mb-0">12 June 2020</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Yuxin Ding, Xiao Zhang,  Wenting Xu</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 7 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1007%2Fs11277-022-09765-0/MediaObjects/11277_2022_9765_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1007/s11277-022-09765-0" data-track="click" data-track-action="click recommendations" data-track-label="10.1007/s11277-022-09765-0">An Efficient Android Malware Detection Using Adaptive Red Fox Optimization Based CNN</a></h3>
                                        <p class="u-sans-serif u-mb-0">29 June 2022</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">P. C. Senthil Mahesh &amp; S. Hemalatha</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 8 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1007%2Fs10586-021-03490-2/MediaObjects/10586_2021_3490_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1007/s10586-021-03490-2" data-track="click" data-track-action="click recommendations" data-track-label="10.1007/s10586-021-03490-2">A federated approach to Android malware classification through Perm-Maps</a></h3>
                                        <p class="u-sans-serif u-mb-0">04 February 2022</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Gianni DAngelo, Francesco Palmieri &amp; Antonio Robustelli</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                    <div class="c-recommendations-list__item" role="group" aria-roledescription="slide" aria-label="Recommendation 9 of 9">
                        <article class="u-full-height c-card c-card--flush">
                            <div class="c-card__layout u-full-height">
                                
                                    <div class="c-card__image"><img src="//media.springernature.com/w136h75/springer-static/image/art%3A10.1007%2Fs10489-022-03523-2/MediaObjects/10489_2022_3523_Fig1_HTML.png" alt=""></div>
                                
                                <div class="c-card__body u-display-flex u-flex-direction-column">
                                    <div class="c-recommendations-column-switch">
                                        <h3 class="c-card__title-recommendation u-h4"><a class="c-card__link" href="https://doi.org/10.1007/s10489-022-03523-2" data-track="click" data-track-action="click recommendations" data-track-label="10.1007/s10489-022-03523-2">Self-attention based convolutional-LSTM for android malware detection using network traffics grayscale image</a></h3>
                                        <p class="u-sans-serif u-mb-0">20 April 2022</p>
                                    </div>
                                    <p class="c-recommendations-authors u-hide-at-sm u-sans-serif">Limin Shen, Jiayin Feng,  Yuying Wang</p>
                                </div>
                            </div>
                        </article>
                    </div>
                    
                </div>
            </div>
        </section>
    </div>
    <div class="js-greyout-page-background" style="display:none" data-component-grey-background></div>
        <script>
            window.dataLayer = window.dataLayer || [];
            window.dataLayer.push({
                recommendations: {
                    recommender: 'semantic',
                    model: 'specter',
                    policy_id: 'BootstrappedUCB',
                    timestamp: 1679248665
                }
            });
        </script>
    
</div>

                </div>
            

            
            <div class="c-pdf-button__container u-hide-at-lg js-context-bar-sticky-point-mobile">
                
    <div class="c-pdf-container">
        <div class="c-pdf-download u-clear-both u-mb-16">
            <a href="/content/pdf/10.1007/s11042-022-14236-6.pdf?pdf=button" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" data-track-external download>
                
                    <span class="c-pdf-download__text">Download PDF</span>
                    <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
                
            </a>
        </div>
    </div>


            </div>
            

            <div class="c-article-collection__container">
                
    

            </div>


            <article lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2022-12-14">14 December 2022</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="">EfficientNet deep learning meta-classifier approach for image-based android malware detection</h1>
                        <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Vinayakumar-Ravi" data-author-popup="auth-Vinayakumar-Ravi" data-corresp-id="c1">Vinayakumar Ravi<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a><sup class="u-js-hide"><a href="#Aff1">1</a></sup> &amp; </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Rajasekhar-Chaganti" data-author-popup="auth-Rajasekhar-Chaganti">Rajasekhar Chaganti</a><sup class="u-js-hide"><a href="#Aff2">2</a></sup></li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/11042" data-track="click" data-track-action="journal homepage" data-track-category="article body" data-track-label="link"><i data-test="journal-title">Multimedia Tools and Applications</i></a>

                             (<span data-test="article-publication-year">2022</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
            
                <li class=" c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">291 <span class="c-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
            
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                    </li>
                
            
            <li class="c-article-metrics-bar__item">
                <p class="c-article-metrics-bar__details"><a href="/article/10.1007/s11042-022-14236-6/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
            </li>
        </ul>
    </div>
</div>

                        </div>
                        
    

    

                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>A survey of literature shows that transforming the application files into images and employing deep learning-based models for image classification has been considered as one of the significant directions for malware detection and classification. Mainly, convolutional neural networks (CNN)-based models are successfully employed for Android malware detection and classification. This is mainly due to the reason that this type of malware detection and classification approach is platform independent and has the capability to detect metamorphic and polymorphic malware. The Image-based Android malware detection is resilient to both unpacked and packed malware. Following, this work employs various 26 CNN-based pretrained models and the detailed investigation and analysis of experiments are shown on the Image-based Android malware dataset. Each of these models have the capability to extract its own optimal features and these features are distinct to each other. The penultimate layer features of best performed CNN-based pretrained models are extracted and dimensionality of the features were reduced using kernel principal component analysis (KPCA). The reduced features were fused together and passed into a meta-classifier or stacked classifier for classification. This classifier has two levels; in the first level support vector machine (SVM) and random forest (RForest) machine learning classifier were included for prediction and logistic regression in the second level for classification. The four combinations of fused models are DenseNet, ResNet, InceptionResNet, and EfficientNet. EfficientNet-based fused models showed better performances compared to other fused models and non-fused CNN-based pretrained models. Moreover, the EfficientNet-based fused models outperformed the existing approaches for Android malware detection. All the model performances were shown on two different testing datasets and the proposed model has shown the similar performances on both the testing datasets with attaining better performances during training and testing. This indicates that the proposed model is more generalizable, robust, and it can be used as tool that can be deployed in any application play store.</p></div></div></section>
                    
    


                    

                    <div data-test="cobranding-download">
                    
                    </div>

                    <div class="app-checklist-banner--on-mobile">
                        
                            
                                
    <div class="app-checklist-banner" data-test="article-checklist-banner">
        <div class="app-checklist-banner__body">
            <h3 class="app-checklist-banner__title">Working on a manuscript?</h3>
            <a class="app-checklist-banner__link" data-track="click" data-track-category="pre-submission-checklist" data-track-action="clicked article page checklist banner test 2 old version" data-track-label="link" href="https://beta.springernature.com/pre-submission?journalId=11042"
            data-test="article-checklist-banner-link">Avoid the common mistakes
            <svg class="app-checklist-banner__arrow-icon" aria-hidden="true" focusable="false">
                <use xlink:href="#icon-springer-arrow-right"></use>
            </svg>
            </a>
        </div>
        <div class="app-checklist-banner__icon-container">
        <svg class="app-checklist-banner__paper-icon" aria-hidden="true" focusable="false">
            <use xlink:href="#icon-checklist-banner"></use>
        </svg>
        </div>
    </div>

                            
                        
                    </div>

                    
                        
                            <div class="main-content">
                            <section data-title="Introduction"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1"><span class="c-article-section__title-number">1 </span>Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>With the proliferation of hardware technology in terms of chip size, processing speed, and capacity over the years, the digital device technology trend shifted towards mobile phones compared to desktop devices. Mobile phones dominating the technology display devices market share and covering the majority market share of 58% in comparison with 42% desktop devices. The smartphone has become popular recently to use like a mini computer with additional capabilities such as embedded sensors, app stores to get numerous mobile applications. The 99% mobile operating systems on the mobile phones are running either Android or iPhone operating systems [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Galov N (2021) 21+ Exciting android statistics to keep your eyes on in 2021" href="/article/10.1007/s11042-022-14236-6#ref-CR13" id="ref-link-section-d365043526e314">13</a>]. Google Android operating system [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Android Malware (2021) Volume statistics, 16 March 2021. &#xA;                https://www.statista.com/statistics/680705/global-android-malware-volume/&#xA;                &#xA;              " href="/article/10.1007/s11042-022-14236-6#ref-CR1" id="ref-link-section-d365043526e317">1</a>] has become popular because vast number of mobile applications available to download from app stores and the operating system is open source. As per the latest statistics in mobile operating system market share worldwide, 71% of the mobile are Android operating systems. As the most number of users use Android based devices, the attacker target to find vulnerabilities in Android devices, distribute malicious apps through app stored to infect the malware and steal the confidential data. For instance, recently ERMAN Android banking Trojan targeting users to steal financial data from 378 banking and wallet apps [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Lakshmanan R (2021) New android malware steals financial data from 378 banking and wallet apps" href="/article/10.1007/s11042-022-14236-6#ref-CR25" id="ref-link-section-d365043526e320">25</a>]. AV-Test [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Malware (2021) Statistics, 16 March 2021. &#xA;                https://www.av-test.org/en/statistics/malware/&#xA;                &#xA;              " href="/article/10.1007/s11042-022-14236-6#ref-CR27" id="ref-link-section-d365043526e323">27</a>] reports that the number of malicious applications has risen exponentially over the years and it is shown in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig1">1</a>. Furthermore, there are more than 11,000 malicious Android apps appearing each day targeting individuals and companies. So, the Android based devices have become a sweet spot for attackers to infect with malware.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="563"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>The malware growing trend over the last decade</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Android malware detection techniques has evolved over the period with advancement in technologies such as machine learning and deep learning [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Vinayakumar R, Soman KP, Poornachandran P (2017) Deep android malware detection and classification. In: 2017 International conference on advances in computing, communications and informatics (ICACCI). IEEE, pp 16771683" href="/article/10.1007/s11042-022-14236-6#ref-CR44" id="ref-link-section-d365043526e350">44</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Vinayakumar R, Soman KP, Poornachandran P, Sachin Kumar S (2018) Detecting android malware using long short-term memory (lstm). J Intell Fuzzy Syst 34(3):12771288" href="/article/10.1007/s11042-022-14236-6#ref-CR45" id="ref-link-section-d365043526e353">45</a>]. The earliest malware detections rely on the static analysis of the suspicious file. This detection process is no different from portable executable (PE) and Executable linkable format (ELF) static analysis based malware detection. The file properties such as file hash, file headers are investigated to find the exact match of malware signatures for malware determination. These detection mechanisms cannot identify the new malware variants with no history and sophisticated malware using code obfuscation techniques are easily evade the static feature signature based detection. The anomaly based detection techniques suffer from number of false positives. In a production malware detection environment, the workforce is required to constantly tune the false positive alerts. The suspicious file realistic behavioral features are captured in dynamic file analysis. Although the dynamic analysis features enable to more accurately detect the hard to detect malware, the feature generation is an extensive process and time-consuming to capture the file behavior in Android sandbox environment. The static, dynamic or the combination of static and dynamic features applied to machine learning and deep learning based Android malware detection is well explored in the literature for effective Android malware detection [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Rehman Z-U, Khan SN, Muhammad K, Lee JW, Lv Z, Baik SW, Shah PA, Awan K, Mehmood I (2018) Machine learning-assisted signature and heuristic-based detection of malwares in android devices. Comput Electr Eng 69:828841" href="/article/10.1007/s11042-022-14236-6#ref-CR34" id="ref-link-section-d365043526e356">34</a>]. But, the feature engineering takes time and efforts, and detecting complex and intelligent malware is much more challenging with these techniques. Additionally, the detection feature selection is dependent on the platform support running the file for malware detection. The hybrid malware analysis techniques rely on the static and dynamic features extracted from the Android APK file. This technique require additional efforts to extract both static and dynamic features and selection of the right feature set is the key for accurate, efficient Android malware detection.</p><p>Although the machine learning and deep learning based Android malware detection solutions with static and dynamic based feature selection able to detect new variants and unknown malware, it requires feature engineering and polymorphic based malware with little changes in the source are difficult to detect. The obfuscated malware can easily evade the detection models if the adversary is aware of the features used for the detection. Additionally, for machine learning based detection, the subject expert knowledge is required to scrutinize the Android malware behavior and extract the right set of the features using both static and dynamic analysis. Recent literature survey shows a rapid increase in the number of malware due to the advancement in technologies and hackers wanting to get into the networks using malicious programs with the aim to compromise the connected devices and use them to infect others also. Also, hackers are finding new ways and advancing their malicious programs to evade defense mechanisms. Most importantly, the existing studies show that these malwares are variants of existing malware family [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Vinayakumar R, Alazab M, Soman KP, Poornachandran P, Venkatraman S (2019) Robust intelligent malware detection using deep learning. IEEE Access 7:4671746738" href="/article/10.1007/s11042-022-14236-6#ref-CR43" id="ref-link-section-d365043526e362">43</a>]. Mostly, the variants are generated by making changes to the malware code or by using executable packers. Also, complex techniques such as encryption and decryption, compression, and hybrid of both compression and encryption and decryption techniques are also employed to create variants of the existing malware family. The variants of the same malware family exhibit structural and visual similarity. In order to alleviate all these problems with static and dynamic analysis, we have considered the Image-based Android malware detection model. In particular, for malware classification, the same malware family exhibit the same image layout and texture and easy to distinguish the malware families. The Image-based detection also has an advantage of platform independent malware detection. Furthermore, the Image-based Android malware detection methods require no additional feature processing and a malware to image conversion mechanism is sufficient to capture the malware features.</p><p>Some of the works explored the application of malware detection using malware or benign file to image conversion techniques [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Venkatraman S, Alazab M, Vinayakumar R (2019) A hybrid deep learning image-based analysis for effective malware detection. J Inf Secur Appl 47:377389" href="/article/10.1007/s11042-022-14236-6#ref-CR42" id="ref-link-section-d365043526e368">42</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Vinayakumar R, Alazab M, Soman KP, Poornachandran P, Venkatraman S (2019) Robust intelligent malware detection using deep learning. IEEE Access 7:4671746738" href="/article/10.1007/s11042-022-14236-6#ref-CR43" id="ref-link-section-d365043526e371">43</a>] in Linux and Windows based systems. The malware executable is transformed into image space on which machine learning or deep learning models are applied for efficacious malware detection [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Vinayakumar R, Alazab M, Soman KP, Poornachandran P, Venkatraman S (2019) Robust intelligent malware detection using deep learning. IEEE Access 7:4671746738" href="/article/10.1007/s11042-022-14236-6#ref-CR43" id="ref-link-section-d365043526e374">43</a>]. Few of the works also focussed on applying the Image-based detection for Android malware [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Rahali A, Lashkari AH, Kaur G, Taheri L, Gagnon F, Massicotte F (2020) DIDroid: android malware classification and characterization using deep image learning. PervasiveHealth: Pervasive Comput Technol Healthcare:7082" href="/article/10.1007/s11042-022-14236-6#ref-CR33" id="ref-link-section-d365043526e377">33</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Ren Z, Wu H, Ning Q, Hussain I, Chen B (2020) End-to-end malware detection for android iot devices using deep learning. Ad Hoc Netw 101:102098" href="/article/10.1007/s11042-022-14236-6#ref-CR35" id="ref-link-section-d365043526e380">35</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Singh J, Thakur D, Ali F, Gera T, Kwak KS (2020) Deep feature extraction and classification of android malware images. Sensors 20(24):7013" href="/article/10.1007/s11042-022-14236-6#ref-CR37" id="ref-link-section-d365043526e384">37</a>]. These works focused on applying either machine learning or deep learning techniques in the images datasets extracted from the Android malware and benign dataset. The malware detection performance has a scope to improve for Image-based Android malware detection in the prior art [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Ren Z, Wu H, Ning Q, Hussain I, Chen B (2020) End-to-end malware detection for android iot devices using deep learning. Ad Hoc Netw 101:102098" href="/article/10.1007/s11042-022-14236-6#ref-CR35" id="ref-link-section-d365043526e387">35</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Singh J, Thakur D, Ali F, Gera T, Kwak KS (2020) Deep feature extraction and classification of android malware images. Sensors 20(24):7013" href="/article/10.1007/s11042-022-14236-6#ref-CR37" id="ref-link-section-d365043526e390">37</a>]. Recent literature shows that the deep learning model performances are better in various applications [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Awotunde JB, Ajagbe SA, Oladipupo MA, Awokola JA, Afolabi OS, Mathew TO, Oguns YJ (2021) An improved machine learnings diagnosis technique for covid-19 pandemic using chest x-ray images. In: International conference on applied informatics. Springer, pp 319330" href="/article/10.1007/s11042-022-14236-6#ref-CR3" id="ref-link-section-d365043526e393">3</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Kumar TA, Rajmohan R, Pavithra M, Ajagbe SA, Hodhod R, Gaber T (2022) Automatic face mask detection system in public transportation in smart cities using iot and deep learning. Electronics 11(6):904" href="/article/10.1007/s11042-022-14236-6#ref-CR23" id="ref-link-section-d365043526e396">23</a>]. In this work, we have performed the detail investigation of the various deep learning CNN based models for Android malware detection and considered the EfficientNet based CNN pretrained model for performance improvement. The meta-classifier and feature fusion based approaches capture the multi aspects of the malware features and can improve the detection performance. So, we have proposed a framework, which combines the CNN pretrained model i.e. EfficientNet, feature fusion, and meta-classifier techniques for robust and effective detection and classification of the Android malware. To the end, the main contributions of the proposed work are given below 
</p><ul class="u-list-style-dash">
              <li>
                <p>This work proposes a deep learning-based meta-classifier approach for Image-based Android malware detection.</p>
              </li>
              <li>
                <p>The detailed investigation and analysis of various 26 CNN-based pretrained models are done for Android malware detection using Image-based data samples.</p>
              </li>
              <li>
                <p>The dimension of penultimate layer features of the best performed CNN-based models are reduced using KPCA.</p>
              </li>
              <li>
                <p>To enhance the model performance for Android malware detection, feature fusion approach was employed on the reduced features of penultimate layer of best performed CNN-based pretrained models.</p>
              </li>
              <li>
                <p>Meta-classifier or stacked classifier was employed on the fused features for Android malware detection.</p>
              </li>
              <li>
                <p>The detailed investigation and analysis of all the models are shown on two testing datasets with the aim to achieve generalization.</p>
              </li>
              <li>
                <p>t-distributed stochastic neighbour embedding (t-SNE) visualization approach was employed to ensure that the learned features by the proposed method were meaningful for Android malware detection.</p>
              </li>
              <li>
                <p>The performance of the proposed method is compared with the existing methods and shown that the proposed method is robust and performs better than the existing Image-based Android malware detection.</p>
              </li>
            </ul></div></div></section><section data-title="Literature survey"><div class="c-article-section" id="Sec2-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec2"><span class="c-article-section__title-number">2 </span>Literature survey</h2><div class="c-article-section__content" id="Sec2-content"><p>Android malware detection has been a vivid area of research for security researchers because the threat actors keep changing their tactics to evade the detection and also actors able to reach out to the number of users by deploying the malicious applications in app stores for exploitation. The Android application is shipped as a zipped APK file to install on the mobile device. The zip file is wrapped with various files such as manifest file, class.dex file, resources file, etc. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Singh J, Thakur D, Gera T, Shah B, Abuhmed T, Ali F (2021) Classification and analysis of android malware images using feature fusion technique. IEEE Access, vol 9" href="/article/10.1007/s11042-022-14236-6#ref-CR38" id="ref-link-section-d365043526e458">38</a>]. An adversary manipulate these files to inject the malware for user device infection. Muzzaffar et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Muzaffar A, Hassen HR, Lones MA, Zantout H (2022) An in-depth review of machine learning based android malware detection. Comput Secur:102833" href="/article/10.1007/s11042-022-14236-6#ref-CR29" id="ref-link-section-d365043526e461">29</a>] performed a review of ML based approaches used in Android malware detection. The supervised, unsupervised, online and deep learning based approached discussed and categorized according to the type of the features extracted for ML training. The authors concluded that the ML models has advantage to effectively detect the malware compared to the traditional malware detection techniques. Historically, the static and dynamic feature extracted from those files are used along with the machine learning and deep learning algorithms for Android malware detection and classification [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Darus FM, Ahmad NA, Mohd Ariffin AF (2019) Android malware classification using xgboost on data image pattern. In: 2019 IEEE international conference on internet of things and intelligence system (iotaIS). IEEE, pp 118122" href="/article/10.1007/s11042-022-14236-6#ref-CR8" id="ref-link-section-d365043526e464">8</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="De Oliveira AS, Sassi RJ (2020) Chimera: an android malware detection method based on multimodal deep learning and hybrid analysis" href="/article/10.1007/s11042-022-14236-6#ref-CR10" id="ref-link-section-d365043526e467">10</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Singh J, Thakur D, Gera T, Shah B, Abuhmed T, Ali F (2021) Classification and analysis of android malware images using feature fusion technique. IEEE Access, vol 9" href="/article/10.1007/s11042-022-14236-6#ref-CR38" id="ref-link-section-d365043526e470">38</a>]. Most importantly, Image-based malware detection methods were studied by security researchers for accurate detection of malware.</p><p>The detailed literature survey of computer vision based approaches for security applications are studied in detail in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Zhao J, Masood R, Seneviratne S (2021) A review of computer vision methods in network security. IEEE Commun Surveys Tutorials" href="/article/10.1007/s11042-022-14236-6#ref-CR53" id="ref-link-section-d365043526e476">53</a>]. The computer vision based techniques used in phishing detection, traffic anomaly detection, and malware detection. A detailed investigation and analysis of existing studies of malware detection are reviewed and critical analysis done by [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Qiu J, Zhang J, Luo W, Pan L, Nepal S, Xiang Y (2020) A survey of android malware detection with deep neural models. ACM Comput Surv, vol 53(6)" href="/article/10.1007/s11042-022-14236-6#ref-CR31" id="ref-link-section-d365043526e479">31</a>]. Our work is related to the Image-based Android malware detection and detail description of the existing works, advantages, and limitations are provided in this section.</p><p>VisDroid [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Bakour K, nver HM (2020) Visdroid: android malware classification based on local and global image features, bag of visual words and machine learning techniques. Neural Comput Appl:121" href="/article/10.1007/s11042-022-14236-6#ref-CR4" id="ref-link-section-d365043526e485">4</a>] converts Android Manifest.xml files into grayscale images and extracts Image-based features comprising local features like scale-invariant feature transform and speeded up robust features along with global features encompassing colour histogram and Hu moments. Classification of the Android malware samples into the various families is done by training the machine learning classifiers using the above extracted feature subsets. A hybridized ensemble technique has been proposed which exhibits performance enhancements in terms of classification accuracy and computational speedup. However, the best performed vote based method achieved 91% accuracy and still has a room for detection accuracy improvement. Grayscale image patterns were generated by converting .dex class files into binary array sequences in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Chen H, Du R, Liu Z, Xu H (2018) Android malware classification using xgboost based on images patterns. In: 2018 IEEE 4th information technology and mechatronics engineering conference (ITOEC). IEEE, pp 13581362" href="/article/10.1007/s11042-022-14236-6#ref-CR6" id="ref-link-section-d365043526e488">6</a>]. The GIST features are extracted from the grayscale images and build an XGBoost model for Android malware classification. The authors reported that XGBoost model achieved 99.14% accuracy. However, the results has not been validated for large-scale learning and the validity of the performance for new samples need to be determined. Darus et al. in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Darus FM, Salleh NAA, Mohd Ariffin AF (2018) Android malware detection using machine learning on image patterns. In: 2018 Cyber resilience conference (CRC). IEEE, pp 12" href="/article/10.1007/s11042-022-14236-6#ref-CR9" id="ref-link-section-d365043526e491">9</a>] builds machine learning classifiers like k-nearest neighbors (kNN), RForest, and Decision tree (DT) using the 8-bit grayscale images extracted from the .dex files for Android malware visualizations. The performance evaluation of the 3 results show that RForest performs better than KNN and DT. The best performed RForest method still obtained 84% accuracy. Darus et al. in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Darus FM, Ahmad NA, Mohd Ariffin AF (2019) Android malware classification using xgboost on data image pattern. In: 2019 IEEE international conference on internet of things and intelligence system (iotaIS). IEEE, pp 118122" href="/article/10.1007/s11042-022-14236-6#ref-CR8" id="ref-link-section-d365043526e494">8</a>] infers that grayscale images extracted from the data section of the .apk files yield better performance than using the entire classes .dex when trained with XGBoost techniques. However, the number of samples used for this study were relatively low. Arslan and Amd-cnn [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Arslan RS, Amd-cnn MT (2022) Android malware detection via feature graph and convolutional neural networks. Concurrency Computat Pract Experience, p e7180" href="/article/10.1007/s11042-022-14236-6#ref-CR2" id="ref-link-section-d365043526e497">2</a>] converted the Android malware feature vectors into two Dimensional images and trained the images using CNN. The features extracted from the file andriodmanifest.xml of the Android application. The experimental results showed that the authors model obtained a malware detection rate of 96.2%. The performance can still be improved to achieve accurate detection.</p><p>Multimodal visual representations like Grayscale, RGB, CMYK, and HSL were utilized in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Kumar A, Pramod Sagar K, Kuppusamy KS, Aghila G (2016) Machine learning based malware classification for android applications using multimodal image representations. In: 2016 10th International conference on intelligent systems and control (ISCO). IEEE, pp 16" href="/article/10.1007/s11042-022-14236-6#ref-CR22" id="ref-link-section-d365043526e503">22</a>] from the malware APK byte streams. GIST image features were extracted from the visually represented images and trained DT, RForest, and KNN classifiers. The performance results showed that RForest has better performance with 91% accurate detection. However, the performance still far away from ideal detection accuracy. CP-MVCS [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Naeem H, Guo B, Ullah F, Naeem MR (2019) A cross-platform malware variant classification based on image representation. KSII Trans Internet Inf Syst, vol 13(7)" href="/article/10.1007/s11042-022-14236-6#ref-CR30" id="ref-link-section-d365043526e506">30</a>] classifies cross-platform Windows OS and Android OS malware variants by utilizing SIFT-GIST feature extractors. The SIFT-GIST feature is built from the the grayscale images, which are constructed from the malware binaries to train conventional machine learning classifiers. DroidDeep [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Su X, Zhang D, Li W, Zhao K (2016) A deep learning approach to android malware feature learning and detection. In: 2016 IEEE trustcom/bigdataSE/ISPA. IEEE, pp 244251" href="/article/10.1007/s11042-022-14236-6#ref-CR39" id="ref-link-section-d365043526e509">39</a>] is a fast and efficient malware detector which combines static analysis features extracted from apk files. There were 32247 features obtained from manifest, resources, and .dex files and then applied Deep Belief Network (DBN) for feature learning. Finally, SVM is used for Android malware classification. Drioddeep achieved 99.4% detection accuracy. But, 5 different feature types need to be extracted for detection and little information is provided on the large-scale learning. Unver et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="nver HM, Bakour K (2020) Android malware detection based on image-based features and machine learning techniques. SN Appl Sci 2(7):115" href="/article/10.1007/s11042-022-14236-6#ref-CR41" id="ref-link-section-d365043526e512">41</a>] constructed grayscale images from malware and benign apks. The images were applied using SIFT, SURF, KAZE, and ORB techniques to extract the local features, which are then clustered using Kmeans to form local feature histogram vectors and global image features. These features were stacked up and normalized for training various machine learning classifiers for efficient visualization based malware detection. Overall, the Adaboost algorithm performed better than other machine learning techniques to classify the Android benignware and malware. However, the proposed method cannot detect the injection attacks and the performance is impacted by the code obfuscation and manipulation techniques. Yang et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Yang M, Wen Q (2017) Detecting android malware by applying classification techniques on images patterns. In: 2017 IEEE 2nd international conference on cloud computing and big data analysis (ICCCBDA). IEEE, pp 344347" href="/article/10.1007/s11042-022-14236-6#ref-CR48" id="ref-link-section-d365043526e515">48</a>] unzips and rescales apk files into matrix to form grayscale images. The GIST based texture features extracted from images to train a RForest model for malware classification. The Derbin malware dataset was used for the performance evaluation. The detection accuracy has a scope to be improved using advanced computer vision and classification techniques.</p><p>An energy-efficient approach is suggested in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Lachtar N, Ibdah D, Bacha A (2020) Towards mobile malware detection through convolutional neural networks. IEEE Embedded Syst Lett" href="/article/10.1007/s11042-022-14236-6#ref-CR24" id="ref-link-section-d365043526e522">24</a>], which transforms Nave instructions from Android app into images by using Hilbert space-filling curves and entropy based visualization technique for building an efficient CNN based detection system. The authors proposed technique is applied to three CNN architectures LeNet, AlexNet, and InceptionV3 and LeNet achieved the best malware detection accuracy 99.3%. However, the preprocessing step requires converting the .dex code into the OAT file(ahead of time file) using Android runtime system. So, every new sample being tested must go through the runtime process to obtain the OAT file. In [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Dai Y, Li H, Qian Y, Lu X (2018) A malware classification method based on memory dump grayscale image. Digit Investig 27:3037" href="/article/10.1007/s11042-022-14236-6#ref-CR7" id="ref-link-section-d365043526e525">7</a>], memory data dump extracted from cuckoo sandbox dynamic analysis were converted to grayscale images. Feature extracted using bicubic interpolation and histogram of gradients techniques were used to build a multilayer perceptron which provided improved results. But, the dynamic analysis should be performed to extract the memory dump file for each sample. The authors [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Ding Y, Wu R, Xue F (2018) Detecting android malware using bytecode image. In: International conference on cognitive computing. Springer, pp 164169" href="/article/10.1007/s11042-022-14236-6#ref-CR11" id="ref-link-section-d365043526e528">11</a>] utilized CNNs to detect packed malware from byte-code images. The classes .dex files from the Drebin dataset are treated as binary byte streams to be converted into a matrix of fixed length. The results obtained using 4-layer CNN achieved 93.7% detection accuracy. There is still a scope to improve the malware detection performance. In [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="He P, Gan G (2020) Android malicious app detection based on cnn deep learning algorithm. In: IOP conference series: earth and environmental science. IOP publishing, vol 428, pp 012061" href="/article/10.1007/s11042-022-14236-6#ref-CR17" id="ref-link-section-d365043526e531">17</a>], RGBA images are generated by merging malware RGB images with permissions and APK features . Various deep learning variants like CNN and long short-term memory (LSTM) are experimented with RGB and RGBA malware images. The obtained results demonstrate that RGBA image detection with CNN exhibits better performance with 93.4%. The false negatives still need to be reduced to optimum. MixDroid [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Huang W, Hou E, Zheng L, Feng W (2018) Mixdroid: a multi-features and multi-classifiers bagging system for android malware detection. In: AIP conference proceedings. AIP publishing LLC, vol 1967, pp 020015" href="/article/10.1007/s11042-022-14236-6#ref-CR18" id="ref-link-section-d365043526e534">18</a>] utilizes a manifold of features from opcode features and Image-based features to train ensemble techniques with various learners. The authors showed that CNN performed better than the machine learning techniques KNN and SVM. The Mixdriod with multi-feature and multi classifier performed way better than the individual classifiers. Although mixdriod achieved better performance, the multi-feature extraction processing requires time and efforts.</p><p>Inception models with SGD optimizers were explored on grayscale images in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Jung J, Choi J, Cho S-J, Han S, Park M, Hwang Y (2018) Android malware detection using convolutional neural networks and data section images. In: Proceedings of the 2018 conference on research in adaptive and convergent systems, pp 149153" href="/article/10.1007/s11042-022-14236-6#ref-CR21" id="ref-link-section-d365043526e540">21</a>]. The .data section of the apk files is used than the entire .dex files to reduce the storage capacity relatively. The Inception and ResNet with SGD performed better than Inception alone with SGD with accuracy more than 98%. The proposed method only finds malware if it exists in .dex file. End-to-End learning for Android IoT devices is facilitated in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Ren Z, Wu H, Ning Q, Hussain I, Chen B (2020) End-to-end malware detection for android iot devices using deep learning. Ad Hoc Netw 101:102098" href="/article/10.1007/s11042-022-14236-6#ref-CR35" id="ref-link-section-d365043526e543">35</a>]. Resampling techniques are used to preprocess .dex bytecodes into fixed size sequences, which are trained using DexCNN and DexCRNN models, and its variants for effective malware detection. The DexCRNN model has achieved the best performance 95.8% on the datasets. But, the detection accuracy performance can still be improved for Android malware detection. The proposed method has advantages of no feature engineering is required and not limited to any particular file size. However, the large-scale validation of the techniques is considered as one of the future work. Chimera [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="De Oliveira AS, Sassi RJ (2020) Chimera: an android malware detection method based on multimodal deep learning and hybrid analysis" href="/article/10.1007/s11042-022-14236-6#ref-CR10" id="ref-link-section-d365043526e546">10</a>] is a multimodal deep learning based malware detection engine combining CNN, deep neural network (DNN), and transformer networks (TN) to perform fusion based feature learning from raw .dex, static analysis, and dynamic analysis feature data. The multimodel deep learning chimera obtained 90.9% detection accuracy to classify the Android malware. Although the dataset is relatively high compared to the other studies, the detection accuracy still need to be improved.</p><p>SARVOTAM [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Singh J, Thakur D, Ali F, Gera T, Kwak KS (2020) Deep feature extraction and classification of android malware images. Sensors 20(24):7013" href="/article/10.1007/s11042-022-14236-6#ref-CR37" id="ref-link-section-d365043526e552">37</a>] is a lightweight malware detection engine which converts malware binaries into grayscale fingerprint images and then utilizes a CNN for feature extraction. Softmax layer is replaced by various conventional machine learning learners for malware detection. The CNN-SVM variant yielded the best performance with accuracy 92.59%. However, there is still a room to improve the performance of the Android malware or benignware detection. Ding et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Ding Y, Zhang X, Hu J, Xu W (2020) Android malware detection method based on bytecode image. J Ambient Intell Humanized Comput:110" href="/article/10.1007/s11042-022-14236-6#ref-CR12" id="ref-link-section-d365043526e555">12</a>] enables detection of obfuscated malware by preprocessing apk bytecodes to create fixed size matrices, which are being fed to a CNN model for malware detection. The proposed method does not need a decompilation tools and can be used for encrypted malware detection. The experimental evaluation of the authors method achieved 95% detection accuracy.</p><p>Yang et al. in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Yang S (2019) An image-inspired and cnn-based android malware detection approach. In: Proceedings of the 34th IEEE/ACM international conference on automated software engineering, pp 12591261" href="/article/10.1007/s11042-022-14236-6#ref-CR47" id="ref-link-section-d365043526e561">47</a>] provides a novel approach to convert bytecodes to images using Pillow tool and then applied CNN model to detect the malware. Their method achieved 93% detection accuracy for Android malware classification. The advantage of this method is direct use of the byte codes for image generation. The detection performance can be improved for better accuracy. Yen et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Yen Y-S, Sun H-M (2019) An android mutation malware detection based on deep learning using visualization of importance from codes. Microelectron Reliab 93:109114" href="/article/10.1007/s11042-022-14236-6#ref-CR49" id="ref-link-section-d365043526e564">49</a>] converts apk file into its corresponding java code using the dex2jar and jad tool to create values for each word by employing the TF-IDF method. Grouped features are fed to Simhash and djb2 hashing algorithm to generate visual images, which is then fed to a CNN for detection purpose. The proposed method achieved 92% detection accuracy. The training dataset is relatively low, and the there is a scope to improve the performance. Zhang et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Zhang H, Qin J, Zhang B, Yan H, Guo J, Gao F, Wang S, Hu Y (2020) A multiclass detection system for android malicious apps based on color image features. Wirel Commun Mob Comput, vol 2020" href="/article/10.1007/s11042-022-14236-6#ref-CR52" id="ref-link-section-d365043526e567">52</a>] suggests a color image visualization method using TF-IDF to find the influential behavioral features in Android apps. A ResNet architecture is utilized for performing multiclass classification utilizing the 1695 customized malicious features. The proposed method obtained 96% detection accuracy to classify the Android malware. Mercaldo et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Mercaldo F, Santone A (2020) Deep learning for image-based mobile malware detection. J Comput Virology Hacking Tech:115" href="/article/10.1007/s11042-022-14236-6#ref-CR28" id="ref-link-section-d365043526e570">28</a>] follows a hierarchical approach of detecting whether a given input sample is a malware or not, followed by identifying the malware family and its corresponding variant. Bytecodes are transformed into grayscale images from which histogram based features are defined for detection of iOS and Android OS malware. A three layer deep neural network is used to detect the given sample is malware or not. Android malware samples are converted to grayscale images onto which image space adversarial attack techniques like one-pixel and its variants are deployed to generate adversarial malware variants [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Gu S, Cheng S, Zhang W (2020) From image to code: executable adversarial examples of android applications. In: Proceedings of the 2020 6th international conference on computing and artificial intelligence, pp 261268" href="/article/10.1007/s11042-022-14236-6#ref-CR14" id="ref-link-section-d365043526e573">14</a>]. The adversarial counterparts are then transformed into corresponding .dex files which are repacked and resigned as an executable entity. This adversarial executable variant can fool the malware detector utilizing learning techniques to misclassify as a benign entity.</p><p>Recently, The authors in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Guerra-Manzanares A, Bahsi H (2022) On the relativity of time: implications and challenges of data drift on long-term effective android malware detection. Comput Secur, p 102835" href="/article/10.1007/s11042-022-14236-6#ref-CR15" id="ref-link-section-d365043526e579">15</a>] analyzed the cross-device behavioral consistency of Android application dynamic features, i.e., system calls. The reported results indicate that the Android dynamic features extracted from different devices impact the ML-based detection performance on Android datasets. Graph neural networks have been applied to generate API graph embedding and detect the android malware in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Yumlembam R, Issac B, Jacob SM, Yang L (2022) Iot-based android malware detection using graph neural network with adversarial defense. IEEE Internet Things J" href="/article/10.1007/s11042-022-14236-6#ref-CR50" id="ref-link-section-d365043526e582">50</a>]. The GNN model obtained 98.33% accuracy on the CICMaldriod dataset. The authors also proposed GAN based algorithm to attack the GNN-based malware classifier and showed that the GAN-based model reduces the detection rate of the GNN classifier. Jerbi et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Jerbi M, Dagdia ZC, Bechikh S, Said LB (2022) Android malware detection as a bi-level problem. Comput Secur 121:102825" href="/article/10.1007/s11042-022-14236-6#ref-CR20" id="ref-link-section-d365043526e585">20</a>] presented a detection rule as a Bi-level optimization problem for Android malware detection. The lower and upper levels generate a set of artificial malicious patterns, and an efficient co-evolutionary algorithm is used to optimize both levels. However, there is still room for performance improvement using the authors technique in Android malware detection. The authors in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Rafiq H, Aslam N, Ahmed U, Lin JC-W (2022) Mitigating malicious adversaries evasion attacks in industrial internet of things. IEEE Trans Industr Inf" href="/article/10.1007/s11042-022-14236-6#ref-CR32" id="ref-link-section-d365043526e588">32</a>] applied a subset feature selection method to evade the fabricate attacks in the Industrial IoT environment. Then ensemble methods were used to train the independent classification models. The authors reported accuracy of 91% by using the proposed method and tested that the method defends the adversarial evasion attacks. Guerra-Manzanares and Valbe [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Guerra-Manzanares A, Valbe M (2022) Cross-device behavioral consistency: benchmarking and implications for effective android malware detection. Mach Learn Appl, p 100357" href="/article/10.1007/s11042-022-14236-6#ref-CR16" id="ref-link-section-d365043526e591">16</a>] performed a benchmark analysis of the timestamp impact on the drift modeling using six different timestamp-based approaches for static and dynamic features. The authors concluded that the timestamp would impact long-term performance irrespective of the feature types selected for training. All these recent contributions focused on improving the Android detection processes and studied a specific problem to address in Android malware detection. However, none of the works focused on the large-scale Android malware classification problem.</p><p>Overall, based on our study on using the machine learning and deep learning algorithms for Image-based Android malware detection, the feature selection to convert into the image is the key to determine the detection accuracy and CNN based techniques results in good detection performance compared to the machine learning techniques. But, a limited work has been done on utilizing the combination of classifiers and none of the works focused the large-scale Android malware classification.</p><p>The detailed summary of the existing works and their performances for Image-based Android malware detection are included in Table<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s11042-022-14236-6#Tab1">1</a>.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Comparison of the state-of-the-art techniques with proposed technique</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s11042-022-14236-6/tables/1" aria-label="Full size table 1"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>In summary, there are existing approaches for Image-based malware detection using CNN pretrained models. However, these studies havent done a detailed investigation and analysis of the model performance on Image-based Android malware dataset. In addition, the features are not visualized and further investigated. Thus, these models can not be considered as robust and generalizable. Moreover, recent literature survey shows that the deep learning models are vulnerable to various adversarial attacks and hackers are constantly using adversarial machine learning to bypass the deep learning models. Hence, detailed investigation and analysis of performance of models and feature visualization can be considered as an important direction of research work in Android malware detection. Following, in this work, we employ various CNN-based pretrained models and detailed investigation and analysis done on the features. In addition, the performance of the proposed approach and existing models were evaluated on more than one Android malware test dataset to achieve generalization. The features of the proposed approach are visualized using t-SNE and it helps to know the features learned by the proposed model were meaningful.</p></div></div></section><section data-title="Proposed architecture for image-based android malware detection"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3"><span class="c-article-section__title-number">3 </span>Proposed architecture for image-based android malware detection</h2><div class="c-article-section__content" id="Sec3-content"><p>The proposed end-to-end framework for Image-based Android malware detection is shown in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig2">2</a>. The architecture contains three different stages and are discussed below
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Fig. 2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="417"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Proposed end-to-end framework for Image-based Android malware detection</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
              <h3 class="c-article__sub-heading" id="FPar1">Transforming bytecode into images</h3>
              <p>The Android applications are distributed with Android package (APK) file format for installation in Android supported devices. The zipped APK file contains multiple folders and files supporting to build the application for running in the devices. Adversary add malicious code in one of these files to install the malware through the applications in Android devices. The folders and files included in the APK zip file are as follows. 
</p><ul class="u-list-style-dash">
                <li>
                  <p>META-INIF/: It contains SHA1 hash computed for all the files in APK file MANIFEST.MF, the SHA1 has value of MANIFEST.MF file CERT.SF and the signature for the CERT.SF file stored in CERT.RSA.</p>
                </li>
                <li>
                  <p>Assets/: It contains the application assets and these can be retrieved using Assetmanager Object.</p>
                </li>
                <li>
                  <p>Res/: It contains the description of the resources, which are different from the information stored in Resources.asc folder.</p>
                </li>
                <li>
                  <p>Lib/: The supported library files needed to compile the code is resided in this folder.</p>
                </li>
                <li>
                  <p>AndroidManifest.xml: It contains the authorization permissions information used to interact with software, hardware, and other API libraries.</p>
                </li>
                <li>
                  <p>Classes.dex: It contains dalvik byte code, which is generated by compiling the java code. The Dalvik byte code is needed to be executed using Dalvik virtual machine to run the application.</p>
                </li>
                <li>
                  <p>Resources.asc: It contains the compiled APK resources information. The information is stored in XML format.</p>
                </li>
              </ul>
              <p>To get the class.dex file, the application files of Android are decompressed. The class.dex file contains bytecode in the form of hexadecimal format. Further hexadecimal format is split into three 2 digit numbers in the left to right order. Then, each of these numbers is converted into their decimal form and assigned to R, G, and B code in the same order. For example, 646778 is split into 64, 67, and 78, which are then converted into their decimal forms and assigned as (R:100, G:103; B:120). Finally, we obtain Android color images, which are then fed into CNNs to perform Android malware detection. The sample color images of Android benign and malware is shown in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig4">4</a>.</p>
            
              <h3 class="c-article__sub-heading" id="FPar2">Deep learning model information</h3>
              <p>This work employs EfficientNet CNN pretrained model for Android malware detection. The original model was trained on the ImageNet database, which has more than one million images grouped into 1,000 classes. This model has learned rich features which represent images from different classes. Thus, in this work we use this model and fine tune the model on the Android malware image dataset by replacing the last layer with two classes instead of 1,000 classes.</p>
              <p>CNN network models are known to be achieved better performance for image classification with no image feature extraction requirement as an input. To improve the model performance and maintain the same computational efficiency, the network models can be scaled. But, tuning network parameters such as network width, depth, and kernel size require manual effort and time-consuming to run each tuned model for selecting the best model. A balance between the network parameters such as network width, height, image resolution need to be achieved to maintain the high accuracy. So, the authors in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Tan M, Le QV (2019) Efficientnet: rethinking model scaling for convolutional neural networks. CoRR arXiv:&#xA;                1905.11946&#xA;                &#xA;              " href="/article/10.1007/s11042-022-14236-6#ref-CR40" id="ref-link-section-d365043526e1622">40</a>] presented a compound scaling method to effectively scale the all the three network parameters for obtaining the better accuracy and the scaling method is evaluated using the EfficientNet mobile sized baseline network model. We leverage the EfficientNet based CNN model for detecting the Android malware and benignware, in which the Android datasets are represented in the image form. The EfficientNet pretrained models ranging from B0 to B7 are defined based on the scaling parameters to match with the other CNN pretrained models with better performance. The base network model EfficientNetB0 is tuned with network parameter coefficients to obtain the network models B0 to B7. The compound scaling methodology for selecting the network parameters is as follows.
\</p>
              <p>A compound coefficient <i></i> is defined to uniformly select the network width, depth, and resolution. The relation between <i></i> and the denoted network parameters width <i>w</i>, depth <i>d</i>, and resolution <i>r</i> is
</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ d = \alpha^{\phi}; w = \beta^{\phi}; r = \gamma^{\phi} $$</span></div><div class="c-article-equation__number">
                    (1)
                </div></div><p>such that the following condition must satisfy to select the scaling parameters
</p><div id="Equ2" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ \alpha. \beta^{2}. \gamma^{2} \approx 2 $$</span></div><div class="c-article-equation__number">
                    (2)
                </div></div><div id="Equ3" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ \alpha \geq 1, \beta \geq 1, \gamma \geq 1 $$</span></div><div class="c-article-equation__number">
                    (3)
                </div></div>
              <p>The EfficientNetB0 contains several mobile inverted bottleneck MBConv stages and convolution layers. The detail description of the various MBConv layers with different kernel sizes are shown in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig3">3</a>. The last convolution layer, pooling, and fully connected are not shown in the Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig3">3</a>, as transfer learning is used for Android malware detection in our framework. There were 3 stages with kernel size 3x3 and 3 stages with kernel size 5x5 in each MBConv stage. The MBconv stage layers also has squeeze and extraction layer to improve the channel dependencies. The switch activation <i>R</i><i>e</i><i>L</i><i>U</i> and batch normalization across each stage is used in the model.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Fig. 3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="413"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>EfficientNet model for Android Malware Detection</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
            
              <h3 class="c-article__sub-heading" id="FPar3">Feature extraction, feature dimension reduction, and fusion</h3>
              <p>EfficientNet use a series of convolutional and max-pooling layers, followed by two or more fully connected layers. However, the fully connected layers contain the most number of parameters and thus carry the risk of overfitting and hindering the models generalization ability. In addition, these layers are heavily dependent on dropout regularization to reduce overfitting. To overcome this, we replace the topmost fully connected layer in the CNN with a Global average pooling (GAP) layer. GAP layer utilization results in excellent localization, which can give an idea about where neural networks pay attention. Even though the main aim of the model was classification, by looking at the areas where the network paid attention, this method can achieve good results in malware region localization. We extract the features of the GAP layer from EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB5, and EfficientNetB6. The dimensions of EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB5, and EfficientNetB6 are 1280, 1280, 1408, 2048, and 2304 respectively. The dimension of the extracted feature is large and difficult to interpret. Moreover, the large dimension of features causes noise and difficulties in achieving best classification performance. Since the features are highly non-linearly separable, KPCA was employed on the extracted features individually. The reduced features of EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB5, and EfficientNetB6 are 640, 640, 704, 512, and 512 respectively. Further, these features are merged together. The recent literature survey shows that there are many methods available for feature fusion and analysis of the performance of these models on the extracted features from various EfficientNet models can be considered as one of the significant directions towards future work.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-a" data-title="Algorithm 1"><figure><figcaption><b id="Figa" class="c-article-section__figure-caption" data-test="figure-caption-text">Algorithm 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/a" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Figa_HTML.png?as=webp"><img aria-describedby="Figa" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Figa_HTML.png" alt="figure a" loading="lazy" width="685" height="926"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-a-desc"><p>Image-based Android malware classification.</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/a" data-track-dest="link:Figurea Full size image" aria-label="Full size image figure a" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
            
              <h3 class="c-article__sub-heading" id="FPar4">Classification</h3>
              <p>For classification, stacked classifier or meta-classifier was employed. Stacking is an ensemble learning approach that combines more than one individual classifier via a meta-classifier [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Wolpert DH (1992) Stacked generalization. Neural Netw 5(2):241259" href="/article/10.1007/s11042-022-14236-6#ref-CR46" id="ref-link-section-d365043526e1895">46</a>]. The individual classifiers are trained on the complete training set in the first stage and then, the meta-classifier is fitted based on the outputs of the classifiers of the first stage in the second stage. The classifiers in the first stage are complex, and the classifier included in the second stage is simple. In the current work, the first stage of stacking classifier contains SVM and RForest classifiers for prediction and logistic regression in the second stage for classification. SVM is a supervised machine learning algorithm used for classification and regression. For classification problems, the SVM considers each data point in an n-dimensional plane and segregates them two classes. The hyperplane line is selected based on the maximum margin among the two classes data points to distinguish the two classes. The kernel selection plays an important role for achieving the good performance. The commonly used kerenl are rbf, linear, and poly. RForest randomly construct multiple decision trees and apply the input datasets. The output classification of each decision tree is considered to perform the ensemble learning to determine the final output. One of the well-known ensemble method used in classification is the maximum number of RForest voted for any particular class is considered as the outcome for the given input. The logistic regression is the probability modeling of the outcome given an input variable. Logical regression can be used for solving binary or multi classifier problems. The logistic function will be a sigmoid function taking any input value and classify as 0 or 1 for binary classification. These machine learning are used in our framework to perform the meta-classifier based feature fusion malware detection.</p>
              <p>The most important SVM parameters and its values are tolerance =0.0001, max iter =5000, kernel= linear, and regularization parameter C = 1.0. Similar to SVM, the important parameters and its values of RForest are n_estimators =100 and max depth =200. Random state is set to 100 for both SVM and RForest. Logistic regression classifier parameters and its value are tolerance =0.0001, max_iter =100, and C = 1.0. The other set of parameters in all three classifiers use default values provided by scikit-learn.</p>
              <p>The step by step approach of the proposed approach for Image-based Android malware detection is shown in Algorithm 1. The proposed model takes image samples as input and outputs a value as either benign or malware.</p>
            </div></div></section><section data-title="Description of android malware dataset"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4"><span class="c-article-section__title-number">4 </span>Description of android malware dataset</h2><div class="c-article-section__content" id="Sec4-content"><p>Though there are many published Image-based Android malware studies exist, there are a few studies that have made their dataset publicly available for research purposes. This work has obtained the dataset from R2-D2 [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Huang TH-D, Kao H-Y (2018) R2-d2: color-inspired convolutional neural network (cnn)-based android malware detections. In: 2018 IEEE international conference on big data (big data). IEEE, pp 26332642" href="/article/10.1007/s11042-022-14236-6#ref-CR19" id="ref-link-section-d365043526e1913">19</a>]. It contains color images collected from about 2 million legitimate and malware Android applications during Jan. 2017 to Aug. 2017. The image size is about 10-50kb with dimension 299x299. The 24 bits of color image preserves more complex information than the 8-bit grayscale image. The detailed statistics of the dataset is shown in Table<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s11042-022-14236-6#Tab2">2</a>. There are two testing datasets, testing-1 contains both the legitimate and malware image samples and testing-2 contains only malware image samples. The testing-1 dataset was used to test the performance of the trained models and testing-2 dataset was used to assess the generalization of the models. A sample of benign and malware samples are shown in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig4">4</a>.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Summary of Android malware image dataset</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s11042-022-14236-6/tables/2" aria-label="Full size table 2"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Fig. 4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="367"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Randomly chosen image samples from Android malware dataset. The first row includes image samples for benign and second row for malware</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div></div></div></section><section data-title="Performance metrics"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5"><span class="c-article-section__title-number">5 </span>Performance metrics</h2><div class="c-article-section__content" id="Sec5-content"><p>To evaluate the performances of the deep learning-based models for Image-based Android malware detection, the following metrics are considered in this study. 
</p><ul class="u-list-style-dash">
              <li>
                <p>Accuracy is the classifiers ability to classify all positive samples as positive and all negative samples as negative.
</p><div id="Equ4" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ Accuracy = \frac{TP + TN}{TP + TN + FP + FN} $$</span></div><div class="c-article-equation__number">
                    (4)
                </div></div>
              </li>
              <li>
                <p>Precision is a measure of the classifiers ability to not mark a negative sample as positive.
</p><div id="Equ5" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ Precision = \frac{TP}{TP + FP} $$</span></div><div class="c-article-equation__number">
                    (5)
                </div></div>
              </li>
              <li>
                <p>Recall is a measure of the classifiers ability to mark all positive samples as positive.
</p><div id="Equ6" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ Recall = \frac{TP }{TP + FN} $$</span></div><div class="c-article-equation__number">
                    (6)
                </div></div>
              </li>
              <li>
                <p>F1-Score is the weighted average of Precision and Recall.
</p><div id="Equ7" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$ F1score = 2 \times \frac{Precision \times Recall}{Precision + Recall} $$</span></div><div class="c-article-equation__number">
                    (7)
                </div></div>
              </li>
            </ul><p>where TP, FP, TN, and FN are true positive, false positive, true negative and false negative respectively. The values for TP, FP, TN, FN are obtained from confusion matrix. It is a 2x2 confusion matrix that displays and compares actual values with the predicted values. The details of TP, TN, FP, and FN are given below 
</p><ul class="u-list-style-dash">
              <li>
                <p>TP: the number of malware image samples classified as malware.</p>
              </li>
              <li>
                <p>TN: the number benign image samples classified as benign.</p>
              </li>
              <li>
                <p>FP: the number of benign image samples classified as malware.</p>
              </li>
              <li>
                <p>FN: the number of malware image samples classified as benign.</p>
              </li>
            </ul><p>To know the performance of the model at class level for Android malware detection, Precision, Recall, and F1-Score were considered in this work. Precision, Recall, and F1-Score were included for both macro average and weighted average. Macro metric computes the Precision, Recall, and F1-Score for each class and returns the average without considering the proportion for each class in the Android malware image dataset. The weighted metric computes the Precision, Recall, and F1-Score for each class and returns the average by considering the proportion for each class in the Android malware image dataset.</p></div></div></section><section data-title="Results and discussions"><div class="c-article-section" id="Sec6-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec6"><span class="c-article-section__title-number">6 </span>Results and discussions</h2><div class="c-article-section__content" id="Sec6-content"><p>The CNN-based pretrained models were implemented using TensorFlow<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup> as back end with Keras<sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup> front end library and scikit-learn<sup><a href="#Fn3"><span class="u-visually-hidden">Footnote </span>3</a></sup> was used for implementing machine learning algorithms. The experiments for all the models were run on Google Colab<sup><a href="#Fn4"><span class="u-visually-hidden">Footnote </span>4</a></sup> with K80 GPU with 25 GB RAM.</p><p>Firstly, various CNN-based pretrained models such as DenseNet121, DenseNet169, DenseNet201, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7, InceptionResNetV2, InceptionV3, MobileNet, MobileNetV2, NASNetLarge, NASNetMobile, ResNet50, ResNet50V2, ResNet101, ResNet101V2, ResNet152, ResNet152V2, VGG16, and VGG19 were trained on Android malware training dataset. During training, the experimental parameters such as batch size: 64, learning rate: 0.001, optimizer: Adam, epochs: 10 has been set up for all the models to perform the experiments. The data samples of Android malware dataset were shuffled during training and all the CNN-based pretrained models were initialized with ImageNet pretrained model weights. Most of the models have reached better performance at epoch 6 and there was no improvement after that till 10 epochs. Also, we continue the training till 15 but there was no significant improvement in training accuracy and training loss. Thus we decided to set the epochs parameter value to 10. The training accuracy and loss curve for the CNN-based best performed models such as EfficientNet (EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB5, and EfficientNetB6) and other existing methods such as VGG16 [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Bakour K, nver HM (2021) Deepvisdroid: android malware detection by hybridizing image-based features with deep learning techniques. Neural Comput Appl 33(18):1149911516" href="/article/10.1007/s11042-022-14236-6#ref-CR5" id="ref-link-section-d365043526e2516">5</a>], VGG19 [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Huang TH-D, Kao H-Y (2018) R2-d2: color-inspired convolutional neural network (cnn)-based android malware detections. In: 2018 IEEE international conference on big data (big data). IEEE, pp 26332642" href="/article/10.1007/s11042-022-14236-6#ref-CR19" id="ref-link-section-d365043526e2519">19</a>], and InceptionV3 [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Bakour K, nver HM (2020) Visdroid: android malware classification based on local and global image features, bag of visual words and machine learning techniques. Neural Comput Appl:121" href="/article/10.1007/s11042-022-14236-6#ref-CR4" id="ref-link-section-d365043526e2522">4</a>] shown in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig5">5</a>. Also, Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig5">5</a> contains the training accuracy and loss of CNN-based pretrained models for Android malware detection. Most of the CNN-based models showed similar performances in terms of training accuracy and loss except VGG models. Overall, EfficientNet (EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB5, and EfficientNetB6) model showed better training accuracy and loss compared to all other models. These plots helped us to know the convergence and learning capability of the model. The trainable, non-trainable parameter details for all the CNN-based models are included in Table<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s11042-022-14236-6#Tab3">3</a>.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Fig. 5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="758"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Training accuracy and loss plots of 26 pretrained CNN models for Image-based Android malware detection</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 CNN-based pretrained models parameter details</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s11042-022-14236-6/tables/3" aria-label="Full size table 3"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Next, the trained models were evaluated on the test dataset for Android malware detection. The detailed performances were reported in Table<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s11042-022-14236-6#Tab4">4</a>. The results for all the models were reported in both macro and weighted. Most of the EfficientNet models showed better Precision, Recall, and F1-Score with more than 90% except EfficientNetB3, EfficientNetB4, and EfficientNetB7. Similar to EfficientNet, DenseNet models such as DenseNet121, DenseNet169, and DenseNet201 showed Precision, Recall, and F1score above 85%. The ResNet models such as ResNet101V2, ResNet152, and ResNet152V2 showed above 90% performances in terms Precision, Recall, and F1-Score. However, other ResNet models such as ResNet50 and ResNet50V2 had Precision, Recall, and F1-Score in the range 70% to 85%. ResNet101 performed poor compared to other ResNet models and other CNN-based pretrained models. MobileNet, MobileNetV2, and NASNetLarge models showed lesser performances in terms of Precision, Recall, and F1-Score in the range 50% to 60%. NASNetMobile performed better compared to MobileNet, MobileNetV2, and NASNetLarge with 10% higher performances of Precision, Recall, and F1-Score. Overall, the MobileNet, MobileNetV2, NASNetLarge, and NASNetMobile models were showed lesser performances compared to other CNN-based pretrained models such as DenseNet, ResNet, and InceptionNet. InceptionV3 model performance better than EfficientNetB3, EfficientNetB4, EfficientNetB7, ResNet101, ResNet50V2, ResNet50, MobileNet, MobileNetV2, NASNetLarge, and NASNetMobile with Precision, Recall, and F1-Score in the range 85%-90%. Next, the Inception and ResNet model combined and it is called as InceptionResNetV2 and that increased the performance in terms Precision, Recall, and F1-Score from 85%-90% to 95%-97%.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 CNN-based pretrained model results for Android malware classification</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s11042-022-14236-6/tables/4" aria-label="Full size table 4"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Further, to enhance the performances of the CNN-based pretrained model for Android malware detection, the feature fusion approach was employed. The results reported in Table<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s11042-022-14236-6#Tab4">4</a> shows that the performances obtained by similar models were almost closer and some of the models had larger range. For example the performances obtained by EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB5, and EfficientNetB6 are almost closer but EfficientNetB3, EfficientNetB4, EfficientNetB5 models had larger different range. Similar to EfficientNet, the performances obtained by DenseNet models such as DenseNet121, DenseNet169, and DenseNet201 were almost closer. Similar to EfficientNet and DenseNet, ResNet101V2, ResNet152, and ResNet152V2 model performances were closer and ResNet model performances had larger range. Each of these models have the capability to obtain its own features and these features are unique. There may be possibility that the feature fusion of these models can enhance the performance of the Android malware detection. Thus, we follow the following combinations of models for feature fusion:
</p><ul class="u-list-style-dash">
              <li>
                <p>Model-1: DenseNet169 and DenseNet201 features were fused together and called as Model-1.</p>
              </li>
              <li>
                <p>Model-2: Model-2 is a merged feature set of ResNet101V2, ResNet152, and ResNet152V2.</p>
              </li>
              <li>
                <p>Model-3: Model-2 is merged with InceptionResNetV2 and called as Model-3.</p>
              </li>
              <li>
                <p>Model-4: Various EfficientNet models such as EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB5, and EfficientNetB6 were fused together and called as Model-4.</p>
              </li>
            </ul><p>The literature survey shows that combined model of Inception and ResNet can enhance the performances compared to Inception and ResNet individual models. Thus we decided to include the InceptionResNetV2 with the ResNet best performed models and called as Model-3. All the DenseNet models were combined together and called as Model-1. Model-4 is a combination of best performed models of EfficientNet. The performances of these models in terms of Precision, Recall, and F1-Score in both macro and weighted were included in Table<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s11042-022-14236-6#Tab5">5</a>. Model-4 based on EfficientNet performed better than the Model-3, Model-2, and Model-1. Model-1 and Model-2 performances were same and Model-3 performance was better than Model-1 and Model-2 and lesser than Model-4. Overall, the the fused models of CNN-pretrained models performed better than the single CNN-based pretraiend models. Model-4 showed the highest Precision, Recall and F1-Score with more than 99%. This model can be employed in real-time in any app store for detection of Android malware.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 CNN based pretrained model with feature fusion and meta-classifier results for Android malware classification</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s11042-022-14236-6/tables/5" aria-label="Full size table 5"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Confusion matrix for CNN-based pretrained models for Android malware detection is shown in Figs.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig6">6</a> and<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig7">7</a>. The best performed model confusion matrix is shown in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig7">7</a>(d) and other proposed models such as Model-1, Model-2, and Model-3 is shown in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig7">7</a>(a),<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig7">7</a>(b), and (c) respectively. The existing models such as VGG16, VGG19, InceptionV3 confusion matrix for Android malware detection is included in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig6">6</a>(a), (b), and (c) respectively. Model-1, Model-2, Model-3, and Model4 performances in terms of accuracy and misclassification rate are 0.9743 and 0.0257, 0.9726 and 0.0274, 0.9783 and 0.0217, and 0.9879 and 0.0121 respectively. Overall, Model4 has less misclassification rate compared to Model-1, Model-2, Model-3 and other existing models such as VGG16, VGG19, and InceptionV3. In Model-4, 10 benign samples were predicted as malware and 5 malware samples were predicted as benign. Further investigation has to be done to avoid these misclassification and can be considered as future work. The existing studies model such as VGG16, VGG-19, and InceptionV3 showed lesser accuracy and higher misclassification rate compared to the proposed models such as Model-1, Model-2, Model-3, and Model-4. VGG-19 has successfully classified all the benign samples as benign and completely failed to detect even a single malware file as malware. Similar to VGG-19, VGG-16 misclassified 41 benign samples as malware and 189 malware samples as benign with 0.8150 accuracy and 0.1850 misclassification rate. InceptionV3 model has performed better than the VGG16 and VGG19 with less misclassification rate i.e. 0.1210 and better accuracy i.e. 0.8790.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Fig. 6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig6_HTML.png?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="783"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Confusion matrix of existing methods for Image-based Android malware detection</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7" data-title="Fig. 7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig7_HTML.png?as=webp"><img aria-describedby="Fig7" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig7_HTML.png" alt="figure 7" loading="lazy" width="685" height="791"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Confusion matrix of pretrained CNN models for Image-based Android malware detection</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/7" data-track-dest="link:Figure7 Full size image" aria-label="Full size image figure 7" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><p>Though the proposed model such as Model-4 has showed more than 99% performance in terms of Accuracy, Precision, Recall, F1-Score with less misclassification rate, the model is black box and there is no evident that the model will perform better on another completely unseen dataset. Thus in this study, all the trained models of Android malware performances were evaluated on the another Android malware dataset called as testing-2. This dataset contains only malware samples and the total number samples is 12247. Model-4 is able to detect 12237 malware out of 12247 and this performance is better compared to all the other models. The existing models such as VGG16, VGG19, and InceptionV3 was detected 8879, 0, and 9894 malware samples respectively out of 12247. This indicates that the model achieves generalization and it has the capability to show similar performances on any of the completely unseen Android malware dataset.</p><p>CNN-based finetuned model for Android malware detection are complex and can be considered these models as black-box. Recent literature survey shows that the deep learning models are not robust in an adversarial environment. Model interpretation plays an important role along with achieving the best performance. t-SNE is a simple and effective method for model interpretation and this can be used for hidden layer feature visualization. The t-SNE representation for best performed model on Android malware detection testing-1 dataset in shown in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig8">8</a>. The feature dimension of the proposed model is 3008, and this was passed into t-SNE. It implicitly uses PCA to reduce the dimensionality of features into two dimensions. These two dimensions are two principal components shown in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig8">8</a><i>X</i>-axis and <i>Y</i> -axis respectively. This type of visualization allowed us to verify the benign and malware image samples of Android OS in separate clusters. Figure<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s11042-022-14236-6#Fig8">8</a> shows that the image data samples of benign and malware samples of Android OS are highly non-linearly separable. There are many overlapping regions between the benign and malware image data samples. This indicates that further study is required to analyze the misclassified Android benign and malware application image data samples, and further development is needed to minimize misclassification. This can be considered as one of the significant directions towards future work.
</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8" data-title="Fig. 8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig8_HTML.png?as=webp"><img aria-describedby="Fig8" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11042-022-14236-6/MediaObjects/11042_2022_14236_Fig8_HTML.png" alt="figure 8" loading="lazy" width="685" height="549"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Feature visualization using t-SNE</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s11042-022-14236-6/figures/8" data-track-dest="link:Figure8 Full size image" aria-label="Full size image figure 8" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div></div></div></section><section data-title="Conclusion and future works"><div class="c-article-section" id="Sec7-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec7"><span class="c-article-section__title-number">7 </span>Conclusion and future works</h2><div class="c-article-section__content" id="Sec7-content"><p>This work presents an EfficientNet based feature fusion approach for Image-based Android malware detection. The penultimate layer features of EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB5, and EfficientNetB6 are extracted and following KPCA was employed for dimensionality reduction. After that the features were fused together and passed into a meta-classifier or stacked classifier. The meta or stacked classifier contains two stages; in first stage RForest and SVM were included for prediction and logistic regression in second stage for classification. The proposed model obtained an accuracy of 0.9879 and misclassification rate 0.0121. With the aim to show that the proposed model is generalizable, the model performance were evaluated on additional 12247 malware data samples. The proposed model is able to detect 12,237 malware data samples. Overall, the proposed model performance is good and outperformed other 25 CNN based pretrained models and other fused models from DenseNet, ResNet and InceptionResNet. Also, the proposed model has showed better performances compared to the existing system. The proposed Image-based Android malware detection is platform independent and has the capability to detect metamorphic and polymorphic malware. Also, the Image-based Android malware detection is resilient to both unpacked and packed malware.</p><p>The proposed Android malware detection approach does not rely on binary code analysis and executing the binaries in a virtual environment. Hence, Image-based Android malware detection is faster than static, dynamic, and hybrid analysis. Though the signature based methods are accurate in detecting and classifying the malware, this cannot be a good approach because continuously the signature database has to be updated by malware domain experts. This is time consuming, expensive, and most importantly completely fails to detect the new malware or even variants of the existing malware. As the recent malwares are variants of existing malware families, they are self-similar in nature. Image-based Android malware detection approaches are effective in handling similar malware images and can give more information about the structure of the malware. Image-based Android malware detection approaches are data-driven and these methods analysis based on existing malware. Thus, Image-based Android malware detection doesnt meet a zero day attack and the proposal of a novel approach to deal with a zero day attack can be considered as a significant direction towards future work. Also, Image-based Android malware detection does not give much information about the actual behavior of the malware other than the label given by Antivirus software. There can be another subsystem that can give actual behaviour of the malware and this subsystem can be integrated to the Image-based Android malware detection. This is another future direction of the proposed Android malware detection work.</p><p>The recent literature survey shows that the deep learning models are vulnerable to various adversarial attacks. Mainly hackers are using adversarial machine learning as an approach to bypass the deep learning models. Thus, the proposed models of the current work should be evaluated in an adversarial environment [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Selvaganapathy S, Sadasivam S, Ravi V (2021) A review on android malware: attacks countermeasures and challenges ahead. J Cyber Secur Mobility:177230" href="/article/10.1007/s11042-022-14236-6#ref-CR36" id="ref-link-section-d365043526e5307">36</a>]. This can be considered as one of the significant directions towards the future work. In addition, detailed analysis and investigation required for feature fusion as there are many well-known feature fusion approaches published by researchers.</p></div></div></section>
                            </div>
                        
                    

                    <section data-title="Data Availability Statement"><div class="c-article-section" id="data-availability-statement-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="data-availability-statement">Data Availability Statement</h2><div class="c-article-section__content" id="data-availability-statement-content">
            
            <p>Data will be made available on reasonable request</p>
          </div></div></section><section data-title="Code Availability"><div class="c-article-section" id="code-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="code-availability">Code Availability</h2><div class="c-article-section__content" id="code-availability-content">
            
            <p>Programming codes implemented in this study are available from the first author upon request.</p>
          </div></div></section><section data-title="Notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1" data-counter="1."><div class="c-article-footnote--listed__content"><p><a href="https://www.tensorflow.org/">https://www.tensorflow.org/</a></p></div></li><li class="c-article-footnote--listed__item" id="Fn2" data-counter="2."><div class="c-article-footnote--listed__content"><p><a href="https://keras.io/">https://keras.io/</a></p></div></li><li class="c-article-footnote--listed__item" id="Fn3" data-counter="3."><div class="c-article-footnote--listed__content"><p><a href="https://scikit-learn.org/">https://scikit-learn.org/</a></p></div></li><li class="c-article-footnote--listed__item" id="Fn4" data-counter="4."><div class="c-article-footnote--listed__content"><p><a href="https://colab.research.google.com">https://colab.research.google.com</a></p></div></li></ol></div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Android Malware (2021) Volume statistics, 16 March 2021. <a href="https://www.statista.com/statistics/680705/global-android-malware-volume/">https://www.statista.com/statistics/680705/global-android-malware-volume/</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Arslan RS, Amd-cnn MT (2022) Android malware detection via feature graph and convolutional neural networks. Concurrency Computat Pract Experience, p e7180</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">Awotunde JB, Ajagbe SA, Oladipupo MA, Awokola JA, Afolabi OS, Mathew TO, Oguns YJ (2021) An improved machine learnings diagnosis technique for covid-19 pandemic using chest x-ray images. In: International conference on applied informatics. Springer, pp 319330</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Bakour K, nver HM (2020) Visdroid: android malware classification based on local and global image features, bag of visual words and machine learning techniques. Neural Comput Appl:121</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Bakour K, nver HM (2021) Deepvisdroid: android malware detection by hybridizing image-based features with deep learning techniques. Neural Comput Appl 33(18):1149911516</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s00521-021-05816-y" data-track-action="article reference" href="https://doi.org/10.1007%2Fs00521-021-05816-y" aria-label="Article reference 5" data-doi="10.1007/s00521-021-05816-y">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Deepvisdroid%3A%20android%20malware%20detection%20by%20hybridizing%20image-based%20features%20with%20deep%20learning%20techniques&amp;journal=Neural%20Comput%20Appl&amp;doi=10.1007%2Fs00521-021-05816-y&amp;volume=33&amp;issue=18&amp;pages=11499-11516&amp;publication_year=2021&amp;author=Bakour%2CK&amp;author=%C3%9Cnver%2CHM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Chen H, Du R, Liu Z, Xu H (2018) Android malware classification using xgboost based on images patterns. In: 2018 IEEE 4th information technology and mechatronics engineering conference (ITOEC). IEEE, pp 13581362</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">Dai Y, Li H, Qian Y, Lu X (2018) A malware classification method based on memory dump grayscale image. Digit Investig 27:3037</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.diin.2018.09.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.diin.2018.09.006" aria-label="Article reference 7" data-doi="10.1016/j.diin.2018.09.006">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20malware%20classification%20method%20based%20on%20memory%20dump%20grayscale%20image&amp;journal=Digit%20Investig&amp;doi=10.1016%2Fj.diin.2018.09.006&amp;volume=27&amp;pages=30-37&amp;publication_year=2018&amp;author=Dai%2CY&amp;author=Li%2CH&amp;author=Qian%2CY&amp;author=Lu%2CX">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Darus FM, Ahmad NA, Mohd Ariffin AF (2019) Android malware classification using xgboost on data image pattern. In: 2019 IEEE international conference on internet of things and intelligence system (iotaIS). IEEE, pp 118122</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">Darus FM, Salleh NAA, Mohd Ariffin AF (2018) Android malware detection using machine learning on image patterns. In: 2018 Cyber resilience conference (CRC). IEEE, pp 12</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">De Oliveira AS, Sassi RJ (2020) Chimera: an android malware detection method based on multimodal deep learning and hybrid analysis</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Ding Y, Wu R, Xue F (2018) Detecting android malware using bytecode image. In: International conference on cognitive computing. Springer, pp 164169</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Ding Y, Zhang X, Hu J, Xu W (2020) Android malware detection method based on bytecode image. J Ambient Intell Humanized Comput:110</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Galov N (2021) 21+ Exciting android statistics to keep your eyes on in 2021</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Gu S, Cheng S, Zhang W (2020) From image to code: executable adversarial examples of android applications. In: Proceedings of the 2020 6th international conference on computing and artificial intelligence, pp 261268</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Guerra-Manzanares A, Bahsi H (2022) On the relativity of time: implications and challenges of data drift on long-term effective android malware detection. Comput Secur, p 102835</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Guerra-Manzanares A, Valbe M (2022) Cross-device behavioral consistency: benchmarking and implications for effective android malware detection. Mach Learn Appl, p 100357</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">He P, Gan G (2020) Android malicious app detection based on cnn deep learning algorithm. In: IOP conference series: earth and environmental science. IOP publishing, vol 428, pp 012061</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Huang W, Hou E, Zheng L, Feng W (2018) Mixdroid: a multi-features and multi-classifiers bagging system for android malware detection. In: AIP conference proceedings. AIP publishing LLC, vol 1967, pp 020015</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Huang TH-D, Kao H-Y (2018) R2-d2: color-inspired convolutional neural network (cnn)-based android malware detections. In: 2018 IEEE international conference on big data (big data). IEEE, pp 26332642</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Jerbi M, Dagdia ZC, Bechikh S, Said LB (2022) Android malware detection as a bi-level problem. Comput Secur 121:102825</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cose.2022.102825" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cose.2022.102825" aria-label="Article reference 20" data-doi="10.1016/j.cose.2022.102825">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Android%20malware%20detection%20as%20a%20bi-level%20problem&amp;journal=Comput%20Secur&amp;doi=10.1016%2Fj.cose.2022.102825&amp;volume=121&amp;publication_year=2022&amp;author=Jerbi%2CM&amp;author=Dagdia%2CZC&amp;author=Bechikh%2CS&amp;author=Said%2CLB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Jung J, Choi J, Cho S-J, Han S, Park M, Hwang Y (2018) Android malware detection using convolutional neural networks and data section images. In: Proceedings of the 2018 conference on research in adaptive and convergent systems, pp 149153</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Kumar A, Pramod Sagar K, Kuppusamy KS, Aghila G (2016) Machine learning based malware classification for android applications using multimodal image representations. In: 2016 10th International conference on intelligent systems and control (ISCO). IEEE, pp 16</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">Kumar TA, Rajmohan R, Pavithra M, Ajagbe SA, Hodhod R, Gaber T (2022) Automatic face mask detection system in public transportation in smart cities using iot and deep learning. Electronics 11(6):904</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/electronics11060904" data-track-action="article reference" href="https://doi.org/10.3390%2Felectronics11060904" aria-label="Article reference 23" data-doi="10.3390/electronics11060904">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20face%20mask%20detection%20system%20in%20public%20transportation%20in%20smart%20cities%20using%20iot%20and%20deep%20learning&amp;journal=Electronics&amp;doi=10.3390%2Felectronics11060904&amp;volume=11&amp;issue=6&amp;publication_year=2022&amp;author=Kumar%2CTA&amp;author=Rajmohan%2CR&amp;author=Pavithra%2CM&amp;author=Ajagbe%2CSA&amp;author=Hodhod%2CR&amp;author=Gaber%2CT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24."><p class="c-article-references__text" id="ref-CR24">Lachtar N, Ibdah D, Bacha A (2020) Towards mobile malware detection through convolutional neural networks. IEEE Embedded Syst Lett</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25."><p class="c-article-references__text" id="ref-CR25">Lakshmanan R (2021) New android malware steals financial data from 378 banking and wallet apps</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26."><p class="c-article-references__text" id="ref-CR26">Lekssays A, Falah B, Abufardeh S (2020) A novel approach for android malware detection and classification using convolutional neural networks. In: ICSOFT 2020 - proceedings of the 15th international conference on software technologies, (Icsoft), pp 606614</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27."><p class="c-article-references__text" id="ref-CR27">Malware (2021) Statistics, 16 March 2021. <a href="https://www.av-test.org/en/statistics/malware/">https://www.av-test.org/en/statistics/malware/</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28."><p class="c-article-references__text" id="ref-CR28">Mercaldo F, Santone A (2020) Deep learning for image-based mobile malware detection. J Comput Virology Hacking Tech:115</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29."><p class="c-article-references__text" id="ref-CR29">Muzaffar A, Hassen HR, Lones MA, Zantout H (2022) An in-depth review of machine learning based android malware detection. Comput Secur:102833</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30."><p class="c-article-references__text" id="ref-CR30">Naeem H, Guo B, Ullah F, Naeem MR (2019) A cross-platform malware variant classification based on image representation. KSII Trans Internet Inf Syst, vol 13(7)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31."><p class="c-article-references__text" id="ref-CR31">Qiu J, Zhang J, Luo W, Pan L, Nepal S, Xiang Y (2020) A survey of android malware detection with deep neural models. ACM Comput Surv, vol 53(6)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32."><p class="c-article-references__text" id="ref-CR32">Rafiq H, Aslam N, Ahmed U, Lin JC-W (2022) Mitigating malicious adversaries evasion attacks in industrial internet of things. IEEE Trans Industr Inf</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33."><p class="c-article-references__text" id="ref-CR33">Rahali A, Lashkari AH, Kaur G, Taheri L, Gagnon F, Massicotte F (2020) DIDroid: android malware classification and characterization using deep image learning. PervasiveHealth: Pervasive Comput Technol Healthcare:7082</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34."><p class="c-article-references__text" id="ref-CR34">Rehman Z-U, Khan SN, Muhammad K, Lee JW, Lv Z, Baik SW, Shah PA, Awan K, Mehmood I (2018) Machine learning-assisted signature and heuristic-based detection of malwares in android devices. Comput Electr Eng 69:828841</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.compeleceng.2017.11.028" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.compeleceng.2017.11.028" aria-label="Article reference 34" data-doi="10.1016/j.compeleceng.2017.11.028">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Machine%20learning-assisted%20signature%20and%20heuristic-based%20detection%20of%20malwares%20in%20android%20devices&amp;journal=Comput%20Electr%20Eng&amp;doi=10.1016%2Fj.compeleceng.2017.11.028&amp;volume=69&amp;pages=828-841&amp;publication_year=2018&amp;author=Rehman%2CZ-U&amp;author=Khan%2CSN&amp;author=Muhammad%2CK&amp;author=Lee%2CJW&amp;author=Lv%2CZ&amp;author=Baik%2CSW&amp;author=Shah%2CPA&amp;author=Awan%2CK&amp;author=Mehmood%2CI">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35."><p class="c-article-references__text" id="ref-CR35">Ren Z, Wu H, Ning Q, Hussain I, Chen B (2020) End-to-end malware detection for android iot devices using deep learning. Ad Hoc Netw 101:102098</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.adhoc.2020.102098" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.adhoc.2020.102098" aria-label="Article reference 35" data-doi="10.1016/j.adhoc.2020.102098">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=End-to-end%20malware%20detection%20for%20android%20iot%20devices%20using%20deep%20learning&amp;journal=Ad%20Hoc%20Netw&amp;doi=10.1016%2Fj.adhoc.2020.102098&amp;volume=101&amp;publication_year=2020&amp;author=Ren%2CZ&amp;author=Wu%2CH&amp;author=Ning%2CQ&amp;author=Hussain%2CI&amp;author=Chen%2CB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36."><p class="c-article-references__text" id="ref-CR36">Selvaganapathy S, Sadasivam S, Ravi V (2021) A review on android malware: attacks countermeasures and challenges ahead. J Cyber Secur Mobility:177230</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37."><p class="c-article-references__text" id="ref-CR37">Singh J, Thakur D, Ali F, Gera T, Kwak KS (2020) Deep feature extraction and classification of android malware images. Sensors 20(24):7013</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3390/s20247013" data-track-action="article reference" href="https://doi.org/10.3390%2Fs20247013" aria-label="Article reference 37" data-doi="10.3390/s20247013">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20feature%20extraction%20and%20classification%20of%20android%20malware%20images&amp;journal=Sensors&amp;doi=10.3390%2Fs20247013&amp;volume=20&amp;issue=24&amp;publication_year=2020&amp;author=Singh%2CJ&amp;author=Thakur%2CD&amp;author=Ali%2CF&amp;author=Gera%2CT&amp;author=Kwak%2CKS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38."><p class="c-article-references__text" id="ref-CR38">Singh J, Thakur D, Gera T, Shah B, Abuhmed T, Ali F (2021) Classification and analysis of android malware images using feature fusion technique. IEEE Access, vol 9</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39."><p class="c-article-references__text" id="ref-CR39">Su X, Zhang D, Li W, Zhao K (2016) A deep learning approach to android malware feature learning and detection. In: 2016 IEEE trustcom/bigdataSE/ISPA. IEEE, pp 244251</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40."><p class="c-article-references__text" id="ref-CR40">Tan M, Le QV (2019) Efficientnet: rethinking model scaling for convolutional neural networks. CoRR arXiv:<a href="http://arxiv.org/abs/1905.11946">1905.11946</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41."><p class="c-article-references__text" id="ref-CR41">nver HM, Bakour K (2020) Android malware detection based on image-based features and machine learning techniques. SN Appl Sci 2(7):115</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s42452-020-3132-2" data-track-action="article reference" href="https://doi.org/10.1007%2Fs42452-020-3132-2" aria-label="Article reference 41" data-doi="10.1007/s42452-020-3132-2">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Android%20malware%20detection%20based%20on%20image-based%20features%20and%20machine%20learning%20techniques&amp;journal=SN%20Appl%20Sci&amp;doi=10.1007%2Fs42452-020-3132-2&amp;volume=2&amp;issue=7&amp;pages=1-15&amp;publication_year=2020&amp;author=%C3%9Cnver%2CHM&amp;author=Bakour%2CK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42."><p class="c-article-references__text" id="ref-CR42">Venkatraman S, Alazab M, Vinayakumar R (2019) A hybrid deep learning image-based analysis for effective malware detection. J Inf Secur Appl 47:377389</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20hybrid%20deep%20learning%20image-based%20analysis%20for%20effective%20malware%20detection&amp;journal=J%20Inf%20Secur%20Appl&amp;volume=47&amp;pages=377-389&amp;publication_year=2019&amp;author=Venkatraman%2CS&amp;author=Alazab%2CM&amp;author=Vinayakumar%2CR">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43."><p class="c-article-references__text" id="ref-CR43">Vinayakumar R, Alazab M, Soman KP, Poornachandran P, Venkatraman S (2019) Robust intelligent malware detection using deep learning. IEEE Access 7:4671746738</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/ACCESS.2019.2906934" data-track-action="article reference" href="https://doi.org/10.1109%2FACCESS.2019.2906934" aria-label="Article reference 43" data-doi="10.1109/ACCESS.2019.2906934">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20intelligent%20malware%20detection%20using%20deep%20learning&amp;journal=IEEE%20Access&amp;doi=10.1109%2FACCESS.2019.2906934&amp;volume=7&amp;pages=46717-46738&amp;publication_year=2019&amp;author=Vinayakumar%2CR&amp;author=Alazab%2CM&amp;author=Soman%2CKP&amp;author=Poornachandran%2CP&amp;author=Venkatraman%2CS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44."><p class="c-article-references__text" id="ref-CR44">Vinayakumar R, Soman KP, Poornachandran P (2017) Deep android malware detection and classification. In: 2017 International conference on advances in computing, communications and informatics (ICACCI). IEEE, pp 16771683</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45."><p class="c-article-references__text" id="ref-CR45">Vinayakumar R, Soman KP, Poornachandran P, Sachin Kumar S (2018) Detecting android malware using long short-term memory (lstm). J Intell Fuzzy Syst 34(3):12771288</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.3233/JIFS-169424" data-track-action="article reference" href="https://doi.org/10.3233%2FJIFS-169424" aria-label="Article reference 45" data-doi="10.3233/JIFS-169424">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Detecting%20android%20malware%20using%20long%20short-term%20memory%20%28lstm%29&amp;journal=J%20Intell%20Fuzzy%20Syst&amp;doi=10.3233%2FJIFS-169424&amp;volume=34&amp;issue=3&amp;pages=1277-1288&amp;publication_year=2018&amp;author=Vinayakumar%2CR&amp;author=Soman%2CKP&amp;author=Poornachandran%2CP&amp;author=Sachin%20Kumar%2CS">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46."><p class="c-article-references__text" id="ref-CR46">Wolpert DH (1992) Stacked generalization. Neural Netw 5(2):241259</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0893-6080(05)80023-1" data-track-action="article reference" href="https://doi.org/10.1016%2FS0893-6080%2805%2980023-1" aria-label="Article reference 46" data-doi="10.1016/S0893-6080(05)80023-1">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Stacked%20generalization&amp;journal=Neural%20Netw&amp;doi=10.1016%2FS0893-6080%2805%2980023-1&amp;volume=5&amp;issue=2&amp;pages=241-259&amp;publication_year=1992&amp;author=Wolpert%2CDH">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47."><p class="c-article-references__text" id="ref-CR47">Yang S (2019) An image-inspired and cnn-based android malware detection approach. In: Proceedings of the 34th IEEE/ACM international conference on automated software engineering, pp 12591261</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48."><p class="c-article-references__text" id="ref-CR48">Yang M, Wen Q (2017) Detecting android malware by applying classification techniques on images patterns. In: 2017 IEEE 2nd international conference on cloud computing and big data analysis (ICCCBDA). IEEE, pp 344347</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49."><p class="c-article-references__text" id="ref-CR49">Yen Y-S, Sun H-M (2019) An android mutation malware detection based on deep learning using visualization of importance from codes. Microelectron Reliab 93:109114</p><p class="c-article-references__links u-hide-print"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.microrel.2019.01.007" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.microrel.2019.01.007" aria-label="Article reference 49" data-doi="10.1016/j.microrel.2019.01.007">Article</a>
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20android%20mutation%20malware%20detection%20based%20on%20deep%20learning%20using%20visualization%20of%20importance%20from%20codes&amp;journal=Microelectron%20Reliab&amp;doi=10.1016%2Fj.microrel.2019.01.007&amp;volume=93&amp;pages=109-114&amp;publication_year=2019&amp;author=Yen%2CY-S&amp;author=Sun%2CH-M">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50."><p class="c-article-references__text" id="ref-CR50">Yumlembam R, Issac B, Jacob SM, Yang L (2022) Iot-based android malware detection using graph neural network with adversarial defense. IEEE Internet Things J</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51."><p class="c-article-references__text" id="ref-CR51">Zhang W, Luktarhan N, Ding C, Lu B (2021) Android malware detection using tcn with bytecode image. Symmetry, vol 13(7)</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52."><p class="c-article-references__text" id="ref-CR52">Zhang H, Qin J, Zhang B, Yan H, Guo J, Gao F, Wang S, Hu Y (2020) A multiclass detection system for android malicious apps based on color image features. Wirel Commun Mob Comput, vol 2020</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53."><p class="c-article-references__text" id="ref-CR53">Zhao J, Masood R, Seneviratne S (2021) A review of computer vision methods in network security. IEEE Commun Surveys Tutorials</p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer-com.vtutest.mapmyaccess.com/v2/references/10.1007/s11042-022-14236-6?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section></div><section data-title="Funding"><div class="c-article-section" id="Fun-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Fun">Funding</h2><div class="c-article-section__content" id="Fun-content"><p>Not applicable.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Center for Artificial Intelligence, Prince Mohammad Bin Fahd University, Khobar, Saudi Arabia</p><p class="c-article-author-affiliation__authors-list">Vinayakumar Ravi</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">Department of Computer Science, University of Texas at San Antonio, San Antonio, Texas, 78249, USA</p><p class="c-article-author-affiliation__authors-list">Rajasekhar Chaganti</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Vinayakumar-Ravi"><span class="c-article-authors-search__title u-h3 js-search-name">Vinayakumar Ravi</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=Vinayakumar%20Ravi" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Vinayakumar%20Ravi" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Vinayakumar%20Ravi%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Rajasekhar-Chaganti"><span class="c-article-authors-search__title u-h3 js-search-name">Rajasekhar Chaganti</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=Rajasekhar%20Chaganti" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Rajasekhar%20Chaganti" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Rajasekhar%20Chaganti%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:vravi@pmu.edu.sa">Vinayakumar Ravi</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
            
            
              <h3 class="c-article__sub-heading" id="FPar5">
                <b>Conflict of Interests</b>
              </h3>
              <p>The authors declare no conflict of interest.</p>
            
          </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><h3 class="c-article__sub-heading">Availability of data and material</h3><p>Data used in this study are available from the first author upon request.</p><h3 class="c-article__sub-heading">Publishers note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p>Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.</p><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=EfficientNet%20deep%20learning%20meta-classifier%20approach%20for%20image-based%20android%20malware%20detection&amp;author=Vinayakumar%20Ravi%20et%20al&amp;contentID=10.1007%2Fs11042-022-14236-6&amp;copyright=The%20Author%28s%29%2C%20under%20exclusive%20licence%20to%20Springer%20Science%2BBusiness%20Media%2C%20LLC%2C%20part%20of%20Springer%20Nature&amp;publication=1380-7501&amp;publicationDate=2022-12-14&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s11042-022-14236-6" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s11042-022-14236-6" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Ravi, V., Chaganti, R. EfficientNet deep learning meta-classifier approach for image-based android malware detection.
                    <i>Multimed Tools Appl</i>  (2022). https://doi.org/10.1007/s11042-022-14236-6</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer-com.vtutest.mapmyaccess.com/v2/references/10.1007/s11042-022-14236-6?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-06-20">20 June 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Revised<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-09-12">12 September 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-11-04">04 November 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-12-14">14 December 2022</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1007/s11042-022-14236-6</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span>Cybersecurity</span></li><li class="c-article-subject-list__subject"><span>Cybercrime</span></li><li class="c-article-subject-list__subject"><span>Android</span></li><li class="c-article-subject-list__subject"><span>Malware</span></li><li class="c-article-subject-list__subject"><span>Deep learning</span></li><li class="c-article-subject-list__subject"><span>Transfer learning</span></li><li class="c-article-subject-list__subject"><span>Feature fusion</span></li><li class="c-article-subject-list__subject"><span>Meta-classifier</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                
                <div data-test="download-article-link-wrapper" class="js-context-bar-sticky-point-desktop">
                    
    <div class="c-pdf-container">
        <div class="c-pdf-download u-clear-both u-mb-16">
            <a href="/content/pdf/10.1007/s11042-022-14236-6.pdf?pdf=button" class="u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" data-track-external download>
                
                    <span class="c-pdf-download__text">Download PDF</span>
                    <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
                
            </a>
        </div>
    </div>


                </div>

                
                    
                        
    <div class="app-checklist-banner" data-test="article-checklist-banner">
        <div class="app-checklist-banner__body">
            <h3 class="app-checklist-banner__title">Working on a manuscript?</h3>
            <a class="app-checklist-banner__link" data-track="click" data-track-category="pre-submission-checklist" data-track-action="clicked article page checklist banner test 2 old version" data-track-label="link" href="https://beta.springernature.com/pre-submission?journalId=11042"
            data-test="article-checklist-banner-link">Avoid the common mistakes
            <svg class="app-checklist-banner__arrow-icon" aria-hidden="true" focusable="false">
                <use xlink:href="#icon-springer-arrow-right"></use>
            </svg>
            </a>
        </div>
        <div class="app-checklist-banner__icon-container">
        <svg class="app-checklist-banner__paper-icon" aria-hidden="true" focusable="false">
            <use xlink:href="#icon-checklist-banner"></use>
        </svg>
        </div>
    </div>

                    
                

                <div data-test="collections">
                    
    

                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="u-lazy-ad-wrapper u-mt-16 u-hide" data-component-mpu><div class="c-ad c-ad--300x250">
    <div class="c-ad__inner">
        <p class="c-ad__label">Advertisement</p>
        <div id="div-gpt-ad-MPU1"
             class="div-gpt-ad grade-c-hide"
             data-pa11y-ignore
             data-gpt
             data-gpt-unitpath="/270604982/springerlink/11042/article"
             data-gpt-sizes="300x250" data-test="MPU1-ad"
             data-gpt-targeting="pos=MPU1;articleid=s11042-022-14236-6;">
        </div>
    </div>
</div>

</div>
                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>

    
        <script>
            
        </script>



        
    <footer class="app-footer" role="contentinfo" data-test="springerlink-footer">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" data-cc-action="preferences" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a href="https://support.springer-com.vtutest.mapmyaccess.com/en/support/home">FAQ</a></li>
                <li><a id="contactus-footer-link" href="https://support.springer-com.vtutest.mapmyaccess.com/en/support/solutions/articles/6000206179-contacting-us">Contact us</a></li>
                <li><a href="https://www-springer-com.vtutest.mapmyaccess.com/gp/shop/promo/affiliate/springer-nature">Affiliate program</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 65.2.72.189</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Ekalavya Institute of Technology Ummtturu Grama (3002776046)  - GSSS  Institute of Engineering Technology for Women (3001404442)  - Adichunchanagiri Institute of Technology (3000713187)  - Oxford School of Architecture (3003228838)  - Global Academy of Technology (3000709550)  - Acharya NRV School of Architecture (3002775918)  - Rajiv Gandhi Institute of Technology, Cholanagar (3002150375)  - Malik Sandal Institute of Arts and Architecture (3002776137)  - Vidya Vikas Institute of Engineerin &amp; Technology (3001405848)  - Dr. T. Thimmaiah Institute of Technology (3000782255)  - HMS Institute of Technology (3001432192)  - SJB Institute of Technology, Bengaluru. LIBRARY &amp; INFORMATION CENTRE (3000714778)  - Gopalan School of Architecture and Planning (3003228562)  - RNS School of Architecture (3003228860)  - Bangalore College of Engineering and Technology (3002082790)  - A.C.S. College of Engineering (3000189241)  - KS School of Architecture (3003228752)  - Sampoorna Institute of Technology Technology &amp; Research (3002776044)  - K.S. Institute of Technology (3000696842)  - Vemana Institute of Technology (3000975616)  - B.N.M. Institute of Technology (3000968235)  - Maharaja Institute of Technology Mysore (3001405874)  - Sri Krishna School of Engineering and Management (3001405842)  - Visvesvaraya Technological Univ Regional Centre Bangalore RHCS Layout (3002082616)  - HMS School of Architecture (3003228603)  - Smt Kamala &amp; Sri Venkappa Agadi College Of Engineering &amp; Tech (3001792059)  - J N N College of Engineering (3002159397)  - Reva Institute of Technology &amp; management (3001405802)  - Govt. Engineering College Karawar (3002776172)  - Govt. Engineering College Raichur (3003228564)  - BMS School of Architecture (3002543604)  - Veeerappa Nisty Engineering College (3002147687)  - Shri Madhwa Vadiraja Institute of Technology &amp; Management (3001404359)  - B.V.B. College of Engineering &amp; Technology (3000228645)  - Maharaja Institute of Technology (3003228755)  - Mangalore Institute of Technology and Engineering (3001405871)  - Shridevi Institute of Engineering &amp; Technology (3001433723)  - Jyothy Institute of Technology (3000968260)  - J.S.S. Academy of Technical Education,Bengaluru-560060 (2000695425)  - ATME College of Engeering (3001432091)  - Jain Institute of Technology (3001405882)  - Visvesvaraya Technological University (3001338151)  - CITY Engineering College (3001405725)  - Achutha Institute of Technology (3002776190)  - Cambridge Institute of Technology (3001432117)  - Maratha Mandal&#x27;s Engineering College (3000718804)  - C. Byre Gowda Institute of Technology (3001405714)  - Visvesvaraya Technological Univ Regional Centre Gulbarga (3002082618)  - Shaikh College of Engineering and Technology Bhootramatti (3002082742)  - Best School of Architecture (3002776152)  - Shah-Shib College of Engineering (3002776019)  - KCT Engineering College (3003228750)  - KNS Institute of Technology (3001432199)  - Sri Venkateshwara College Of Engineering (3000707092)  - Vijaya Vittal Institute of Technology Dodda Gubbi Post (3002776201)  - Biluru Gurubasava Mahaswamiji institute of Technology Mudhol (3001405887)  - M.S. Ramaiah Inst. of Technology M.S. Ramaiah Nagar, MSRIT Post (2000628096)  - M.S Engineering College (3001404440)  - Canara Engineering College (3000705224)  - Vivekananda Iinstitute of Technology (3001404542)  - VTU Trial Account (3001412227)  - Visvesvaraya Technological Univ Regional Centre Mudenhalli (3002082670)  - Nitte School of Architecture (3003228778)  - K.L.E. Society&#x27;s College of Engineering &amp; Technology (3000711034)  - SECAB Institute of Engg. &amp; Technology (3002146695)  - P N S Womens Institute of Technology (3002775981)  - Sri Sai Ram College of Engineering (3001665689)  - AICTE Mechanical Engineering e-Jour (3000684257)  - Nitte Meenakshi Institute of Technology (3001445249)  - Tontadarya College Of Engineering (3000716983)  - PA College of Engineering (3001432235)  - Dayananda Sagar Academy of Technology  and Management (3001405888)  - Bangalore Technological Institute (3001404478)  - Dr. M V Shetty Institute of Technology ( MVSIT) (3001405868)  - Lingaraj Appa Engineering College Bidar (3002111260)  - Dr Ambedkar Institute of Technology (3001208153)  - VSM Shri Somashekhar R Kotiwale Institute of Technology (3002082746)  - BLDEAs College of Engineering &amp; Technology (3001405716)  - P.E.S. INSTITUTE OF  TECHNOLOGY BSK 3rd Stage (3000698719)  - Aakar Academy of Architecture (3002776196)  - S D M Institute of Techology Ujire (3001404384)  - PES Institute of Technology (3000699622)  - S L N College of Engineering (3002082718)  - Govt. Engineering College Krishnarajapete Mandya (3002165735)  - PES University (3000696456)  - Vidyavardhaka College of Engg, Mysore,Gokulam,3rd Stage (3000576101)  - Bheemanna Khandre Institute of Technology (3001404544)  - (Nitte) Nmam Institute Of Technology (3001404609)  - G Madegowda Institute of Technology (3002082713)  - East West Institute Of Technology (3000705258)  - Coorg Institute  of Technology (3001404299)  - Sri Revana Siddeshwara Institute of Technology (3000715101)  - Ghousia College of Engineering (3000735822)  - BGS School of Architecture and Planning (3003228519)  - SDM College of Engineering &amp; Technology (2000348493)  - Anjuman Institute of Technology and Management (3001404388)  - Alpha College of Engineering (3002772045)  - Visvesvaraya Technological Univ Regional Centre Mysore Hanchya (3002082619)  - BMS College of Architecture (3003240288)  - SAHYADRI COLLEGE OF ENGINEERING AND MANAGEMENT (3001028409)  - Govt. Engineering College Kushalanagar (3002776114)  - S.J.C INSTIUTE OF TECHNOLOGY (3000699561)  - NDRK Institute of Technology (3002083165)  - Don Bosco Institute of Technology (3000721776)  - APS College of Engineering (3000739515)  - Adithya Academy of Architecture and Design (3003228468)  - RR Institute of Technology (3001432298)  - S J B School of Architecture &amp; Planning BGS Health &amp; Education (3002776206)  - SRINIVAS INSTITUTE OF TECHNOLOGY (3000707094)  - Islamiah Institute of Technology (3002082777)  - SHREE DEVI INSTITUTE OF TECHNOLOGY (3000715069)  - Bapuji Institute of Engineering and Technology (3002082679)  - Govt. Engineering College Haveri (3002776159)  - Sri Vinayaka Institute of Technology (3003228832)  - Proudadevaraya Institute of Technology (3000714739)  - Vishwanathrao Deshpande Institute Of Technology (3000697745)  - M V J College of Engineering (3001405829)  - Bearys Institute of Technology (3001404573)  - Rural Institute of Tech (3002083168)  - National Institute of Engineering (3002094895)  - Kalpataru Institute of Technology (3001404576)  - Mangalore Marine College &amp; Technology (3002776005)  - Yenepoya Institute of Technology (3003228830)  - BMS College of Engineering (2000607897)  - K.V.G. College of Engineering (3000728303)  - AMC Engineering College (3001445178)  - Amruta Institute of Engineering &amp; Management Sciences (3000697620)  - Girijabai Sail Inst of Technology (3001432142)  - KS School of Engineering and Management (3000977954)  - Govt. Engineering College Ramanagara (3002082715)  - AICTE Electrical &amp; Electronics &amp; Computer Science Engineering (3000684219)  - R N S Institute of Technology (3001405884)  - BMS Institute of Technology and Management (3000705221)  - Angadi School of Architecture (3003876978)  - Alvas Institute of Engineering and Technology (3001404444)  - S.J.M. Institute of Technology NH 4 bye-pass (3001990314)  - THE OXFORD COLLEGE OF ENGINEERING (3000707115)  - PNS Institute of Technology (3001432269)  - Srinivas School of Engineering (3001405787)  - Moodlakatte Institute of Technology (3001405878)  - East West College of Engineering (3003228549)  - Channabasaveshwara Institute of Technology (3000716092)  - J A G M Institute of Technology Jagmit (3001405742)  - KLE Institution of Technology (3001405767)  - S.T.J Institute of Technology (3001405721)  - Sir M. Visvesvaraya Institute of Technology (2000607911)  - Anjuman Engineering College (3002082771)  - Appa Institute of Engineering and Technology (3002082675)  - Sri Venkateswara College of Engineering (2000505021)  - Acharya Institute Of Technology (3000699587)  - R.T.E. Societys Rural Engineering College (3000710330)  - Government Engineering College (3003954215)  - RL Jalappa Institute of Technology (3000721794)  - Impact School of Architecture (3002776156)  - Jain College of Engineering Technology &amp; Research (3003957506)  - Sahyadri Institute of Technology N.H. 48 Adyar Mandalore (3000176277)  - Siddaganga Institute of Technology (2000651910)  - Basaveshwar Engineering College (Autonomous), Bagalkote (2000478248)  - RAO BAHADUR Y MAHABALES WARAPPA ENGINEERING COLLEGE (3000712631)  - Brindavan College of Engineering (3000773449)  - Nagarjuna College of Engineering and Technology (3001405865)  - SEA College of Engineering and Technology (3001929083)  - Akshaya Institute of Technology (3001432049)  - JAIN COLLEGE OF ENGINEERING             Tipu Sultan Nagar,  Hunchanatti ineering (3001405864)  - Nandi Institute of Technology, and Management Science (3002082779)  - Bangalore Institute of Technology (2000596435)  - Govt. Tool Room &amp; Training Center (3003228566)  - Basava Kalyan Engineering College (3002082711)  - SAPTHAGIRI COLLEGE OF ENGINEERING (3000715177)  - KLE Dr. M.S.Sheshgiri College of Engineering and Technology (3001434859)  - RR School of Architecture (3003228794)  - Bahubali College of Engineering (3002082775)  - AJ Institute of Engineering and Technology (3003228511)  - Dayananda Sagar College Of Engineering (3000696439)  - Sri Basaveshwara Inst of Technology (3003876849)  - Atria Institute of Technology (3002163984)  - Shri Dharmasthala Manjunatheshwar Educational Society (3003228819)  - New Horizon College of Engineering (3000722494)  - Govt. Tool Room &amp; Training Centre (3002775949)  - Jnana Vikas Institute of Technology (3000993881)  - H K B K Institute of Technology (3002772049)  - Cauvery Institute of Technology (3001404355)  - B V B College of Engg &amp; Tech Librarian (3001386340)  - Gov&#x27;t Engineering College (3002776176)  - Mysore School of Architecture (3003228757)  - RV College of Architecture (3003228797)  - KLEs College of Engineering &amp; Tech (3002776130)  - Wadiyar Centre for Architecture (3003228863)  - University B.D.College of Engineering (3001405807)  - Vivekananda College of Engineering &amp; Technology (3000612157)  - IMPACT College of Engineering  and Applied Science (3001405748)  - Navodaya Institute of Technology (3002111485)  - B.T.L Institute of Technology and Management (3001405723)  - Rural Engineering College Hulkoti (3003228810)  - Hirasugar Institute of Technology (3000725070)  - Mysore Royal Institute of Technology (3003228759)  - UBDT College of Engineering (3000983198)  - Angadi Institute of Technology &amp; Management (3001405839)  - Sir. M. V. School of Architecture (3003228835)  - Jain College of Engineering and Technology (3003228728)  - Saint Joseph College of Engg. &amp; Tech. (3002776002)  - Govt. Engineering College Chamarajanagar (3002776048)  - BGS Institue of Technology (3001432111)  - Visvesvaraya Technological University (3001405906)  - Dr. Sri Sri Sri Shivakumara Mahaswamy College of Engineering (3003228546)  - Government Engineering College (3003954218)  - Bearys Environmental Architecure Design Science (3003228515)  - PDA College Of Engineering (3001405744)  - SSETSG balekundri Institute of Technology (3001405861)  - Shri Pillappa College of Engineerin (3001405901)  - Karavali Institute of Technology (3002776000)  - Shetty Institute of Technology (3003228814)  - PES College of Engineering (3000735856)  - Govt. Engineering College,Hassan (3002776009)  - Mysore College of Engineering and Management (3003228771)  - Yellamma Dasappa Institute of Tech. Raghuvanahalli (3002775890)  - R.V. College of Engineering (2000596485)  - KBN College of Engineering (3001405729)  - Sri Vidya Vinayaka Institute of Technology (3001405778)  - Nadgir Institute of Engineering and Technology (3003228775)  - Sri Krishna Institute of Technology (3001881404)  - Govt Sri Krishnarajendra Silver Jubilee Technological Institute (3001942872)  - Government Engineering College (3003952242)  - Gogte Institute of Technology (3000697987)  - Gopalan College of Engineering and Management (3001404571)  - T. John Institute of Technology (3000742166)  - RAJARAJESWARI COLLEGE OF ENGINEERING (3000711821)  - AGMR College of Engineering &amp; Technology Hubli (3001404578)  - Ballari Institute of Technology and Management (3000711790)  - Guru Nanak Dev Engineering College (3003228569)  - CMR Institute of Technology (3001404386)  - East Point College of Engineering and Technology (3000993859)  - Malnad College of Engineering (3000698707)  - Sambhram Institute of Technology (3001405826)  - Mahaswamy College of Engineering (3002775938)  - Nie Institute of Technology (3000716879)  - Rajeev Institute of Technology (3001404547)  - INDEST-AICTE-Level III (3000168247)  - Cambridge institute of technology (3002775895)  - St. Josephs College Of Engineering And Technology (Palai) (3000699641)  - G.M.Institute Of Technology (3000725056) 
        </p>

    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-b88bf25ad4.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2023 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
    </footer>



    </div>
    
    

    
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 10 10" xmlns="http://www.w3.org/2000/svg">
            <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="currentColor" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
        <symbol id="icon-info" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-success" viewBox="0 0 18 18">
            <path d="M9 0a9 9 0 110 18A9 9 0 019 0zm3.486 4.982l-4.718 5.506L5.14 8.465a.991.991 0 00-1.423.133 1.06 1.06 0 00.13 1.463l3.407 2.733a1 1 0 001.387-.133l5.385-6.334a1.06 1.06 0 00-.116-1.464.991.991 0 00-1.424.119z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-down" viewBox="0 0 16 16">
            <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/>
        </symbol>
        <symbol id="icon-warning" viewBox="0 0 18 18">
            <path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-plus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-minus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-error" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-springer-arrow-left">
            <path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/>
        </symbol>
        <symbol id="icon-springer-arrow-right">
            <path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/>
        </symbol>
        <symbol id="icon-arrow-up" viewBox="0 0 16 16">
            <path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-tick" viewBox="0 0 24 24">
            <path d="M12,24 C5.372583,24 0,18.627417 0,12 C0,5.372583 5.372583,0 12,0 C18.627417,0 24,5.372583 24,12 C24,18.627417 18.627417,24 12,24 Z M7.657,10.79 C7.45285634,10.6137568 7.18569967,10.5283283 6.91717333,10.5534259 C6.648647,10.5785236 6.40194824,10.7119794 6.234,10.923 C5.87705269,11.3666969 5.93445559,12.0131419 6.364,12.387 L10.261,15.754 C10.6765468,16.112859 11.3037113,16.0695601 11.666,15.657 L17.759,8.713 C18.120307,8.27302248 18.0695334,7.62621189 17.644,7.248 C17.4414817,7.06995024 17.1751516,6.9821166 16.9064461,7.00476032 C16.6377406,7.02740404 16.3898655,7.15856958 16.22,7.368 L10.768,13.489 L7.657,10.79 Z"/>
        </symbol>
        <symbol id="icon-expand-image" viewBox="0 0 18 18">
            <path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-close" viewBox="0 0 16 16">
            <path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-right" viewBox="0 0 7 12">
            <path d="M2.782 5 .3 2.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 0 1 1.417 0l4.176 4.177a1.001 1.001 0 0 1 0 1.416l-4.176 4.177a.991.991 0 0 1-1.4.016A1 1 0 0 1 .3 9.481L2.782 7l1.013-.998L2.782 5Z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-checklist-banner" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 56.69 56.69" style="enable-background:new 0 0 56.69 56.69" xml:space="preserve">
            <path style="fill:none" d="M0 0h56.69v56.69H0z"/><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/>
        </symbol>
        <symbol id="icon-get-ftr" viewBox="0 0 24 24">
            <path fill="#0D8D8A" fill-rule="nonzero" d="M24 12c0 6.627-5.373 12-12 12-2.102 0-4.078-.54-5.796-1.49l1.485-1.484A9.96 9.96 0 0 0 12 22c5.523 0 10-4.477 10-10a9.96 9.96 0 0 0-.974-4.31l1.484-1.486A11.946 11.946 0 0 1 24 12ZM12 0c2.102 0 4.079.54 5.797 1.49l-1.485 1.485A9.96 9.96 0 0 0 12 2C6.477 2 2 6.477 2 12c0 1.544.35 3.006.975 4.312L1.49 17.797A11.946 11.946 0 0 1 0 12C0 5.373 5.373 0 12 0Z"/>
            <circle cx="12" cy="12" r="5.333" fill="#096A73"/>
        </symbol>
        <symbol id="icon-github" viewBox="0 0 100 100">
            <path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z" fill="#24292f"/>
        </symbol>
        <symbol id="icon-search-filter" viewBox="0 0 29 29">
            <defs><style>.cls-1{fill:none;}</style></defs><title/><g data-name="Layer 2" id="Layer_2"><path d="M28,9H11a1,1,0,0,1,0-2H28a1,1,0,0,1,0,2Z"/><path d="M7,9H4A1,1,0,0,1,4,7H7A1,1,0,0,1,7,9Z"/><path d="M21,17H4a1,1,0,0,1,0-2H21a1,1,0,0,1,0,2Z"/><path d="M11,25H4a1,1,0,0,1,0-2h7a1,1,0,0,1,0,2Z"/><path d="M9,11a3,3,0,1,1,3-3A3,3,0,0,1,9,11ZM9,7a1,1,0,1,0,1,1A1,1,0,0,0,9,7Z"/><path d="M23,19a3,3,0,1,1,3-3A3,3,0,0,1,23,19Zm0-4a1,1,0,1,0,1,1A1,1,0,0,0,23,15Z"/><path d="M13,27a3,3,0,1,1,3-3A3,3,0,0,1,13,27Zm0-4a1,1,0,1,0,1,1A1,1,0,0,0,13,23Z"/><path d="M28,17H25a1,1,0,0,1,0-2h3a1,1,0,0,1,0,2Z"/><path d="M28,25H15a1,1,0,0,1,0-2H28a1,1,0,0,1,0,2Z"/></g><g id="frame"><rect class="cls-1" height="32" width="32"/></g>
        </symbol>
        <symbol id="icon-book" viewBox="0 0 18 18">
            <path
                d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z"
                fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-submit-open" viewBox="0 0 16 17">
            <path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/>
        </symbol>
    </svg>

<script async src='https://link-springer-com.vtutest.mapmyaccess.com/MapMyAccessProxy.js'></script></body>
</html>
